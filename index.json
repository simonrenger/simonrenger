[{"authors":["admin"],"categories":null,"content":"I am Simon, a Game Programming master student as well as a contractor.\nI am striving for new opportunities to learn and innovate. I love my work as much as I love sharing knowledge with others. I do not shy away from a challenge that involves picking up different roles that move a project forward. I am mainly interested in tools design as well as QA Engineering.\nI am always looking for new opportunities to work on as contractor. Just shoot me an e-mail.\n","date":1655769600,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1655769600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am Simon, a Game Programming master student as well as a contractor.\nI am striving for new opportunities to learn and innovate. I love my work as much as I love sharing knowledge with others. I do not shy away from a challenge that involves picking up different roles that move a project forward. I am mainly interested in tools design as well as QA Engineering.\nI am always looking for new opportunities to work on as contractor.","tags":null,"title":"Simon Renger","type":"authors"},{"authors":null,"categories":["research","gamedev","scripting languages"],"content":"Once, during my work on the sadly never published game Reptoads – a round-based deterministic multiplayer cooperative card game, I got asked by different members of the art and design team: why can’t we have a visual scripting language such as Blueprints or Shader Graph for either the gameplay code or the visuals? My answer was always the same: we don’t have enough time to implement such a tool. This question, however, got stuck in my mind and I started searching for a “Lua” of the visual scripting languages just to find\u0026hellip; nothing. Roughly three years later, the same question kept coming up in different projects, while my answer and my research results stayed the same. This made me curious, why is there no such thing as an embeddable visual scripting language that can be used?\nAsking myself why is there no such language and how would one look like, led me to write my Master thesis with the title: “Investigation into the criteria of embeddability of visual scripting languages within the domain of game development”. In my research paper I composed a list of potential criteria that classify a visual scripting language (VSL) as embeddable. In this article I will go through these criteria and design a hypothetical embeddable VSL, which I called Noodle. This will be Part 1 of a series of articles focused on creating a usable VSL prototype.\nYou might think now: hold on for a second! Aren’t there lots of tools doing similar things? Do we really need to reinvent the wheel?\nYes, your instinct is right, there are some well-known solutions out there like Unreal Engine’s Blueprints or Unity’s Visual Scripting, but you simply cannot take their scripting runtime out and put this into your specific 3D retro shooter game engine. Now you might want to say: okay then, I will just use scripting, there are a lot of scripting languages out there (Lua, luau, wren, daScript, anglescript etc.). That argument is also valid but what happens when you look for a designer to help you with your indie game and all you can find are designers that have only worked with Unity or Unreal before. In those cases, it would be better to tell them that there is a language that works like Blueprints or is less complicated than C#, especially since it is easier to learn a VSL than a normal scripting language, as literature suggests [1]–[3].\nSome thoughts about visual scripting First of all, I need to acknowledge that visual scripting is not the silver bullet for all problems in game development and often does more harm than good, especially when it comes to performance and maintainability (Blueprints from Hell: Share The Horror). I want to stress that this article is not pro or against visual scripting languages but rather sees it as a tool, just as with any other programming language (yes, a VSL is a programming language). Of course, there might be other tools out there that do a specific job better but it always depends on the use case and the requirements. During my Masters in Game Technology, I had the chance to interview industry professionals and one of my participants emphasized that the requirements of the game are the most important factor when deciding what tech to choose when working on a game.\nAnother aspect to consider is what are we intending to use the visual scripting language for. During my research, all my interviewees stated that they see the benefits of a VSL in being able to quickly prototype features and its quick iteration times overall. Also, a VSL is perfectly made for certain tasks such as processing sequences. While for others it might be not the right tool such as performance-critical code passes, unless the graph is compiled to native code and heavily optimized. Moreover, VSLs are used for gluing systems together, as industry experts and literature suggest [$$]. In addition, VSLs are often used to handle UI events, for example in the UI workflow, but also for the game logic in general. They are also used as a domain specific language for workflows such as Shader / Material editing or state machines.\nAll these different aspects of possible use cases make it quite difficult to define the best-fit solution. Since it is not easy to determine the right requirements for each of those fields, the idea is to create a generalized model of a language that can be used for these different aspects. I am fully aware that this might not be the ultimate solution that fits all cases.\nThe basic language concepts I will discuss the core concepts of Noodle by following the result structure of my paper. My paper found five major aspects that are potentially important when designing a language framework with embeddability in mind. My thesis defines them as follows: 1.performance and the identified subcategories, 2.mechanical aspects of embedding software and their respective subcategories, 3.license, 4.documentation, 5.tooling and workflow*.* While we look into each of these aspects, we define what consequences it has for Noodle.\nGeneral design overview\nBefore we dive deep into these findings, I will briefly describe the main characteristics of Noodle. Noodle will be diagram-based [1], [4] which means that the language is graph-based and the execution can be followed by traversing nodes. As my research shows, this is the most commonly used VSL form in game engines, e.g., in Unreal Engine, Unity and Godot [5]–[8]. A popular alternative is the block-based design. A block-based design is used for Scratch and Google’s Blockly [9]–[11] but it is not often used in games. Moreover, Noodle will offer pure nodes, nodes without side effects and nodes that may have side effects [12]. They are differently identified by either having an “execution” wire/connection or just a data flow connection. This allows the dialect designer to decide if they need support for one of these concepts or both, depending on the use case requirements. On its own, the language is not event-based, so a graph can be triggered at any node at any point in time by the runtime. However, the dialect designer can specify nodes that can be triggered. These nodes can be used as entry points which would allow an event-based structure if needed. All these decisions are based on what is common in tools used in the game industry, be it Godot’s visual scripting or Unreal Engine’s Material Editor [8], [13]–[17].\nNoodle’s design idea of being a composable language that one can shape depending on the users’ needs, or how literature would call it “extending” by being an extension language, is greatly inspired by the works of Hisham Muhammad and Roberto Ierusalimschy in their paper about the used API design of the Lua programming language [18]–[21]. Since we are talking about a visual scripting language which logic is expressed in composing visual elements [22], we need some form of specification. In Noodle the dialect is described via a protocol: what nodes it supports, what kind of types are supported, etc. Moreover, Noodle supports internal modules, i.e., subgraphs that can help organizing your graph, as well as external modules, if a module resolve function is provided. If not, only internal modules will work. However, the defined protocol might differ from dialect to dialect, depending on the use of the language. We will talk about the protocol an its uses later.\nThe next few paragraphs will now take the findings of my study and describe the impact they might have on Noodle.\nPerformance\nDevelopment performance One of the most important factors for the game industry is the ability to perform quick iteration cycles and to be able to quickly prototype a feature [23, pp. 956–957] [20], [24]. Many interviewees have expressed the opinion that script hot reloading is a crucial feature they would expect from a VSL. It has been shown also in literature [23] that script hot reloading is a great feature, that supports quick iteration and rapid prototyping. Based on these observations, Noodle will support script hot reloading to empower users with quick prototyping.\nRuntime performance When talking to any game programmer, they will most likely make a similar statement as many of my study participants, that memory is the number one bottleneck in games. Although, it greatly depends on the requirements of the game and how dramatic the runtime performance is influenced by the right memory access patterns or the right allocation strategies. Therefore, it is not surprising that most of the participants expressed their opinions on how memory management should work. The major conclusion is that in a VSL, we know from early on what kind of data we will handle since all inputs and outputs of all nodes are known at translation time, therefore the graph could either allocate a large chunk of memory and manage that like in WebAssembly where “\u0026hellip;opcodes accessing memory are not given addresses, but offsets relative to the beginning of a linear memory segment whose size is always known.” The memory model of Noodle will follow the same mentality and will at the beginning allocate the needed memory through a memory allocator interface that the user can modify, if needed. If memory needs to be accessed in a form of a pointer, Noodle will not be able to do anything with these pointers, so it will just pass them down to native functions that are able to understand them.\nWhen it comes to a scripting language and a VSL, which is nothing else than a subcategory [1], [25], the execution method is important. Robert Nystrom states in both of his books “Crafting interpreters” and “Game programming patterns” [26, p. 17], [27, pp. 155–179] that a tree-walking interpreter, a form of an interpreter that traverses the graph by recursively calling the nodes, is slower than compiling the graph down to bytecode that is executed in a virtual machine (VM) or transpiled to a different source code [26, pp. 16–20], [28], [27, pp. 155–179] ,[23, pp. 52,954-958]. Based on these findings, Noodle will compile to bytecode with the intention that the user can compile a Noodle graph representation to C and compile to native code depending on their platform as a last shipping step (if providing a backend). This transpiling or compiling to native code has been mentioned in the interviews as an important feature. It can also be considered to allow the language to enable hot patching of the native generated code. This means that if something is wrong with the compiled C code, a content update of a bytecode compiled graph can be used to hot patch this part of the code.\nMechanical aspects of embedding software\nAPI design As described in the above-mentioned papers from H.Muhammad and R.Ierusalimschy about the API design of Lua and other scripting languages such as Perl or Python, it can be concluded that an API should be flexible to provide the ability to extend the underlaying language not in a verbose (like Perl) manner, but more in a concise declarative manner. This view is supported by my interviewees who describe that an API should be able to bind, for example, an external editor but should also be small enough to be easily manageable. Moreover, academia as well as the interviewed industry professionals argue that the API should be written in the C programming language or at least provide C foreign function interface, since C is considered as the lingua franca of programming languages [18]–[21]. To provide maximal portability from an API point of view, the header files of Noodle will be written in C99 and the implementation will be done in C11.\nDependencies The game industry is notorious for reinventing the wheel [29], [30] and this problem might stem from the platforms we are catering to and the software we are working with. Therefore, having many dependencies that we need to maintain and maybe port to different platforms is not desired. This is what my research suggests and what an industry professional states in an interview: “When you develop a commercial product, you also need to consider two things. Since dependencies might be taken offline at any time, it is very important to have your own copy of them. Also, for various certification on platforms you need to keep in mind that they perform security audits on those dependencies.”. These insights led to the decision for Noodle to have no external dependencies besides the OS dependencies on the platforms it supports.\nLicense \u0026amp; documentation\nThe game industry caters for many different platforms with different requirements, some are open source, some are not. Therefore, the license needs to be permissive since it is not always possible to open-source certain aspects of the entire codebase due to NDA regulations. This is the reason why Noodle will use the MIT license or the Apache License, Version 2.0, depending on the user’s need.\nBesides the license, a good documentation on how to embed the language into your game framework is needed. My thesis research has shown that it is expected by users for some form of online documentation and samples to exist. Therefore, Noodle should provide online documentation in form of a GitHub Page but also examples on how to bind the language.\nWorkflow \u0026amp; tools\nSo far, none of the categories of embeddability are really different from what one would expect from a regular scripting language. In fact, what literature says is that they are nearly matching, and Software Engineering Stack Exchange confirms it. The major difference explained in literature by B.Myers already in 1989 in “Taxonomies of Visual Programming” [1] and in the works of Nystrom and J.Gregory [23], [27], the biggest challenge for a VSL is the UI/UX aspect and mainly the visual scripting environment (VSE). A VSE can be seen as the integrated development environment (IDE) for VSLs. My thesis concluded that among all aspects, workflow and tooling are the most important.\nUnfortunately, there is not much existing research on what qualifies a good visual scripting environment within the domain of game development. If we look outside of the game industry, there are a few papers on this topic, but they mostly describe the design of visual scripting environments for block-based languages, since they are mainly used for educational purposes. Although the industry professionals participating in my study shared some important insights, proper academic research would be needed to make academic claims. However, for this prototype the statements of industry professionals and the scarce UI / UX research on visual scripting environments will base the foundation for Noodle’s UI / UX.\nThe industry professionals stated that one cannot just use Notepad or Visual Studio to edit the “source code” of a VSL, therefore they would expect either a fully-fletched editor to come with the VSL or a flexible API to allow them to bind an editor themselves. One of the participants stated that they would use the provided editor to get acquainted with the language and then use the API to build their own that matches the paradigms and needs of their own ecosystem. Hence, Noodle will come with a prototype of an editor and a flexible API that allows the user to bind a custom editor.\nFor the first prototype, the language will come with a Visual Studio Code extension that enables the editor to understand Noodle files, while the editor will communicate with the Noodle runtime via the WebSocket API by using the protocol described later. Whenever a change occurs in the editor, the updated graph will be sent to the runtime and the runtime user can decide if it is needed to recompile the current graph and swap it with the new changes. The goal is to provide an embeddable editor view written in C or C++ as an external tool on top of the Noodle APIs.\nThe mentioned WebSocket-based API allows network communication to other software that might be the editor. The VS Code extension will be part of the first prototype to demonstrate this communication feature. A network-based communication might be more suitable for games that separate game runtime and editor runtime, while the API communication via the C interface might be better suited for custom game engines that have a built-in editor. Important to mention is that the WebSocket API is purely optional.\nSince debugging and visualizing what is happening within the VSL has been classified as very important, Noodle should come with an ability to attach a debugger to it. In the first prototype we can try to make use of the VS Code Debugger framework and provide the ability to connect to it.\nA Noodle document will be in JSON format that can be parsed with any JSON parser and can be checked in source control like a normal text file. The main reason why JSON has been chosen is that it provides a better source control management support. Also, it can be diffed without big issues, while for example a binary file format would cause source control issues (google ‘Blueprints and source control’).\nThe Noodle Protocol As mentioned above, Noodle runs on a protocol that gives an overview of what nodes are available and what types can the runtime understand. This indicates that Noodle can be either statically or more dynamically typed, depending on the needs of the dialect designer. The Noodle protocol can be generated via the API and will return either a protocol struct that can be used via the C interface or a JSON representation that can be used otherwise in tools or in the WebSocket API.\nBesides the Noodle protocol that describes the language, there is the noodle file or noodle document – the script file. One can see the protocol like a header file in C or C++ and a noodle file as the source file. The noodle document describes the current file the VM is processing. As mentioned above, each noodle file may contain subgraphs (internal modules) or if enabled, external modules. In principle, every noodle document contains three regions:\nProtocol – this region describes the meta data of the current language dialect. The VM will check this region and verify that the name of the dialect, as well as the version, are matching. If not, the file cannot be passed. Migration can be implemented with this approach.\nGraph – this region describes the actual data of the graph, which includes the modules, nodes, connections, and the data.\nEditor – implementation defined region that can be used to define editor specific data such as position of nodes, etc. This region is not used by the VM in any way.\nThe graph region is the only region where the VM interpreter needs to understand the data of the file, while the protocol region is there to make sure that the noodle file matches this dialect.\nFor more in depth information checkout the Noodle Language Specifications\nNext steps This article has described so far what one could expect from a visual scripting language to define the VM as potentially embeddable and has illustrated this by giving concrete examples per category on the prototype language Noodle. Along the series of articles, we will take this further and go through each step of implementing the language, which will function as practical application of my theoretical study.\nIn the next article we will discuss the protocol and the document design a little bit more but will mainly focus on the API design and the editor implementation in VS code. This will also be the first practical test of the protocol and the API.\nFor more information, follow me on Twitter: Kazum93 or check the Noodle page on GitHub. Also, if you are interested in reading my research paper that I have been referring to all the time, you can find it on ResearchGate or my website.\n[1] B. A. Myers, “Taxonomies of Visual Programming,” 1989.\n[2] M. F. Msiska and L. Van Zijl, “From visual scripting to Lua,” ACM Int. Conf. Proceeding Ser., pp. 94–99, 2012, doi: 10.1145/2389836.2389848.\n[3] M. M. Burnett, “Visual object-oriented programming,” Proc. Conf. Object-Oriented Program. Syst. Lang. Appl. OOPSLA, vol. Part F1296, no. April 1994, pp. 127–129, 1993, doi: 10.1145/260303.261240.\n[4] M. M. Burnett and M. J. Baker, “A Classification System for Visual Programming Languages,” J. Vis. Lang. Comput., vol. 5, no. 3, pp. 287–300, 1994, doi: https://doi.org/10.1006/jvlc.1994.1015.\n[5] E. Games, “Blueprints,” 2021. https://docs.unrealengine.com/4.27/en-US/ProgrammingAndScripting/Blueprints/\n[6] E. Games, “Kismet Visual Scripting.” https://docs.unrealengine.com/udk/Three/KismetHome.html\n[7] Unity Technology, “Bolt Documentation.” https://docs.unity3d.com/bolt/1.4/manual/index.html\n[8] G. Team, “Godot Visual Scripting.” https://docs.godotengine.org/en/stable/getting_started/scripting/visual_script/getting_started.html\n[9] Google, “Blocky.” https://developers.google.com/blockly (accessed Apr. 14, 2022).\n[10] J. Maloney, M. Resnick, N. Rusk, B. Silverman, and E. Eastmond, “The scratch programming language and environment,” ACM Trans. Comput. Educ., vol. 10, no. 4, pp. 1–15, 2010, doi: 10.1145/1868358.1868363.\n[11] MIT, “Scratch.” https://scratch.mit.edu/\n[12] P. Wadler, “The essence of functional ( Invited programming talk ) recursive a compiler language,” Proc. 19th ACM SIGPLANSIGACT Symp. Princ. Program. Lang., pp. 1–14, 1992.\n[13] G. Team, “VisualShaders.” https://docs.godotengine.org/en/stable/tutorials/shading/visual_shaders.html\n[14] “Unreal Engine 4 Material Editor.” https://docs.unrealengine.com/4.27/en-US/RenderingAndGraphics/Materials/Editor/\n[15] Unity Technology, “Shader Graph”, [Online]. Available: https://unity.com/shader-graph\n[16] M. Autodesk, “Maya Node Editor.” [Online]. Available: https://knowledge.autodesk.com/support/maya/learn-explore/caas/CloudHelp/cloudhelp/2019/ENU/Maya-Basics/files/GUID-23277302-6665-465F-8579-9BC734228F69-htm.html\n[17] B. F. Blender 3D, “Shader Editor.” https://docs.blender.org/manual/en/latest/editors/shader_editor.html\n[18] H. Muhammad and R. Ierusalimschy, “C APIs in extension and extensible languages,” J. Univers. Comput. Sci., vol. 13, no. 6, pp. 839–853, 2007.\n[19] H. H. Muhammad, “A study on scripting language APIs,” 2006.\n[20] R. Ierusalimschy, L. H. De Figueiredo, and W. C. Filho, “SPE paper Lua – an extensible extension language,” vol. 6, no. 1996, pp. 635–652, 2015.\n[21] R. Ierusalimschy, L. De Figueiredo, and W. Celes, “The evolution of an extension language: A history of Lua,” Proc. V Brazilian Symp. Program. Lang., vol. 1, no. 1, pp. 1–16, 2001, [Online]. Available: http://www.lua.org/history.html%0Ahttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.15.9210\u0026amp;rep=rep1\u0026amp;type=pdf\n[22] M. Idrees, F. Aslam, K. Shahzad, and S. M. Sarwar, “Towards a Universal Framework for Visual Programming Languages,” Pak. J. Engg. Appl. Sci., vol. 23, no. July, pp. 55–65, 2018, [Online]. Available: https://www.researchgate.net/publication/328191862_Towards_a_Universal_Framework_for_Visual_Programming_Languages\n[23] J. Gregory, Game Engine Architecture, Second Edition, 2nd ed. USA: A. K. Peters, Ltd., 2014.\n[24] R. Ierusalimschy, L. H. de Figueiredo, and W. Celes, “Passing a Language through the Eye of a Needle,” Queue, vol. 9, no. 5, pp. 20–29, 2011, doi: 10.1145/1978862.1983083.\n[25] J. K. Ousterhout, “Scripting: Higher-level programming for the 21st century,” Computer (Long. Beach. Calif)., vol. 31, no. 3, pp. 23–30, 1998, doi: 10.1109/2.660187.\n[26] R. Nystrom, Crafting Interpreters, 1st ed. ‎ Genever Benning. [Online]. Available: https://www.craftinginterpreters.com/\n[27] R. Nystrom, “Game Programming Patterns,” in Game Programming Patterns, Genever Benning, 2014. [Online]. Available: https://books.google.nl/books?id=AnvVrQEACAAJ\n[28] R. Nystrom, “A Virtual Machine,” 2021. https://craftinginterpreters.com/a-virtual-machine.html\n[29] J. G. Guerrero, “Reinventing the wheel,” 2014.\n[30] C. O’Toole-Bateman, “The History of the Game Engine: Part 5 – Reinventing the Wheel.” https://ultimategamingparadise.com/features/series/history-of-the-game-engine/part-5-reinventing-the-wheel/\n","date":1655852400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655852400,"objectID":"9ed054e175c508984fb8a57a4d0bd754","permalink":"/posts/industry_article/","publishdate":"2022-06-22T00:00:00+01:00","relpermalink":"/posts/industry_article/","section":"posts","summary":"Once, during my work on the sadly never published game Reptoads – a round-based deterministic multiplayer cooperative card game, I got asked by different members of the art and design team: why can’t we have a visual scripting language such as Blueprints or Shader Graph for either the gameplay code or the visuals? My answer was always the same: we don’t have enough time to implement such a tool. This question, however, got stuck in my mind and I started searching for a “Lua” of the visual scripting languages just to find\u0026hellip; nothing.","tags":["research","github","cpp","research method","visual scripting languages","scripting languages"],"title":"How could an embeddable visual scripting language look like?","type":"posts"},{"authors":["Simon Renger"],"categories":null,"content":"","date":1655769600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655769600,"objectID":"3a9afb08e7d0d94f6bb3e8fb2337a5ad","permalink":"/publication/master_thesis/","publishdate":"2022-06-21T00:00:00Z","relpermalink":"/publication/master_thesis/","section":"publication","summary":"This paper investigates potential criteria to identify visual scripting languages as embeddable  within the domain of game development. We explore the criteria of embeddability for scripting languages and use them as the base line for the study.","tags":["Visual Scripting Languages","Scripting Languages","Embeddability of Software","Software Engineering","Systematic Review","GitHub","Game Development","Gamedev"],"title":"Investigation into the criteria of embeddability of visual scripting languages within the domain of game development.","type":"publication"},{"authors":null,"categories":["research","gamedev","scripting languages"],"content":"Have you ever stumbled upon job offers where companies are looking for \u0026ldquo;coders\u0026rdquo; or \u0026ldquo;scripters\u0026rdquo;? Every time I see those, I ask myself: what is the difference exactly? How can \u0026ldquo;scripting\u0026rdquo; or \u0026ldquo;coding\u0026rdquo; be different from programming? Is there even a difference? I could keep listing questions, but I am sure you get my point. With this in mind, I got asked a few times why I am using the term \u0026ldquo;scripting language\u0026rdquo; and \u0026ldquo;programming language\u0026rdquo; interchangeably, since they represent different concepts. But wait, are they or are they not the same thing? In order to answer this question, we are going to explore what academia has to say about it and combine it with the perspective of a game programmer. Now, what is a scripting language according to academia?\nWhat is a scripting language? One of the pioneers of the term scripting language is the inventor of Tlc John Ousterhout [1]. Ousterhout defines scripting languages (SL) as programming languages that are intended to work with modules defined in other low-level languages such as C. Moreover, Ousterhout states that they are not meant to be used to write a whole application from scratch. In fact, scripting languages are more often used for plug-and-play situations to enable systems to communicate with each other. The use case of plug and play separates scripting languages from system programming languages [1].\nFrom a game programmer perspective\nOusterhout\u0026rsquo;s explanation aligns with how the game industry looks at scripting languages, where an SL is defined as a programming language which primary purpose is to permit to control and customize the behavior of the underlaying application (game/game engine). Therefore an SL is a high-level programming language implemented in a lower level language, which exposes most of the application (game engine) features to the developer [9, pp. 954-955].\nBased on Ousterhout\u0026rsquo;s point of view, an SL is just a sub form of a programming language which is defined in a lower level programming language. Following this logic, we can argue that C, for example, is a scripting language, since it is just a syntactic sugar of Assembly. But that is a discussion for another time. If you are interested in this topic, you might want to check Dino Oliva et al. C\u0026ndash;: A Portable Assembly Language research paper [2] or Moron Why C Is Not Assembly by James Iry [3]. Anyways, let\u0026rsquo;s get back to the original question: if an SL is just a programming language, what makes it so different than C, for example? Ousterhout\u0026rsquo;s states that the main difference is that SLs are interpreted languages while languages like C or Rust are system programming languages.\nWhat is a system programming language? System programming languages are designed to construct data structures and algorithms from scratch to represent an application. C or Rust are great examples for such languages, since they can be used to construct all possible sorts of data structures due to the fact that essentially, they are a composition of primitive building blocks. Therefore, system programming languages are usually very low level and can represent the most primitive computer elements: words of memory [1]. Moreover, Ousterhout characterizes them as being typed and principally compiled. At the same time, scripting languages are mainly dynamic typed or untyped, and interpreted. [1]\nWhat is an interpreted language? Interpreted languages differ from compiled languages in that they are not compiled from one language into another language. Compiled languages are in general directly executed on the CPU [4, pp. 1–23]. On the other hand, Linda Torczon \u0026amp; Keith Cooper define an interpreter as a system that \u0026ldquo;takes as input an executable specification and processes as output the result of executing the specification\u0026rdquo; [4, p. 3]. Moreover, Linda Torczon \u0026amp; Keith Cooper state that some languages such as Java or Lua use a hybrid approach[4, pp. 1–23]. They compile their source input to a bytecode representation which then gets interpreted by an interpreter, commonly called virtual machine (VM). This mixed-method (also called hybrid method) combines the best of both worlds and can be found in many modern scripting languages [4, pp. 1–23] ,[5, pp. 155–179].\nFrom a game programmer perspective\nHybrid languages are interesting for the game industry since the game industry is pushes computer hardware to its limits to reach maximum performance. This hunt after performance leads to extreme code optimization to keep up with the competition [5, pp. 155–179]. The need for high performance is one of the reasons why languages that are using a mixed-method (hybrid language), such as Lua, are more often used than others.\nWhat are hybrid languages? Hybrid languages are more performant than purely interpreted languages [5, pp. 155–179] [6, pp. 25–26]. A purely interpreted language consumes more memory and may require pointer traversal. Traversing pointers may lead to random memory access and cache misses. On the contrary, compiling the source code to bytecode - a compact representation of source code - leads to dense and linear instructions [5, pp. 155–179]. CPUs prefer those kinds of instructions since they can be loaded quicker into cache lines [5, pp. 155–179] [7, pp. 1–24]. The structure of bytecode leads to higher performance than the purely interpreted language since they are better accessible to the CPU.\nThe hybrid method should not be confused with two of the commonly used compilation methods: just in time compilation (JIT) and ahead of time (AOT) compilation. System programming languages are using AOT compilation while most interpreted languages (such as scripting languages) are often using either JIT or AOT. When compiling with AOT, everything gets compiled before running any function and is therefore known to the program. This also means that if something changes, the entire file needs to be recompiled. JIT, on the other hand, means that functions are compiled on demand, i.e. when they are run first. This reduces the load times of an executable [8]. Lua, for example, supports both: standard Lua is AOT while LuaJit is as the name suggested, a JIT Compiler. Therefore AOT and JIT are different methods of compiling code rather than a classification of different methods of language interpretation.\nFrom a game programmer perspective\nOut of multiple reasons, it is important to know the kind of compilation method a language supports. First, the game industry tries to get the maximum out of the hardware [5, pp. 155–179], which means that performance is very important, as previously mentioned. Looking at AOT and JIT compilation methods, JIT seems appealing since it might reduce the loading times [8]. The problem is that JIT compilation might not work on all platforms the game is shipping on. Some specific platforms such as game consoles might forbid this technique in their technical requirement checklist (TRC). Therefore, compiling everything in advance might be preferred for such platforms. On the other hand, AOT compilation can also enable transpiling, the possibilities to compile to native code or just to C or C++ code that in return can be compiled. The factors if a language is compiling AOT or JIT are important for choosing the right language to solve a problem.\nWhat does it mean if a Scripting Language is a “extension language”? Interpreted SL are widely used in other areas than game development, such as artificial intelligence and web development. Python [10] and JavaScript [11] are great examples for such languages. Python is often used for data processing, such as artificial intelligence [12], while JavaScript is commonly used in web development [11]. Besides, JavaScript is used more frequently in game development [13 , 12]. Both Python and JavaScript are part of the evolution of modern scripting languages from simple command-based languages such as Tcl, a pioneer of scripting languages [1], towards complex, nearly general-purpose scripting languages [14]. SL have been greatly evolving ever since their initial introduction, and their use cases vary from the web to artificial intelligence.\nScripting languages can be separated into subcategories such as extension languages or extensible languages. An extensible language is defined as a language that can be extended through external modules in different languages [14]. In contrast, an extension language defines a scripting language that only works within an embedded environment, which is usually called the host program or host application. Often SL offer support for both types. There are more categories than extension and extensible languages such as shell languages [1, 15 ,16], which are not covered, due the focus on game industry relevance. Further research might be needed to establish whether the choice of other subcategories than extension languages has a significant impact within the game industry when it comes to usage as scripting language for game logic or other internal logic.\nExtension languages are used to extend the host application with extra functionality [14]. The ability to extend the host program requires customization points within the language itself. These customization points enable the host program to provide custom actions within the embedded language. For this reason, extension languages provide next to their own syntax an application program interface (API), which the host application can use to interact with the embedded language [14,15].\nAn excellent example for such languages is Lua. The creators R. Ierusalimschy et al, describe Lua as an extensible extension language [15]. Lua allows the host application to communicate with it via its C API and vice versa. Lua can also be extended by the host application with extra functionality [17]. This is also true for other languages such as wren, angelscript or daScript. They all allow the host application to communicate to the VM layer and vice versa. Some of them even offer native code generation.\nFrom a game programmer perspective\nThe ability to extend the language based on the requirements of the game is important since every game has different requirements. Game engines might want to expose certain functionality to the scripting runtime to empower the scripting environment to communicate to the world created in a higher-level language [9, pp. 954-955]. Lua is a great example for that – on its own, Lua is rather “simple” but once extended, and with its all functionality being exposed from the engine/game to the scripting environment, the language can become extremely powerful and flexible.\nScripting languages ARE programming languages The conclusion, based on what academia shows about scripting languages, is that they ARE programming languages. They are just a subcategory of programming languages such as system programming languages. We are heavily exposed to scripting languages since they are used on a daily basis to orchestra different tasks and glue code from different worlds together.\nReferences [1] J. K. Ousterhout, “Scripting: Higher-level programming for the 21st century,” Computer (Long. Beach. Calif)., vol. 31, no. 3, pp. 23–30, 1998, doi: 10.1109/2.660187.\n[2] C-: A Portable Assembly Language Dino Oliva, T. Nordin,Simon Peyton Jones Proceedings of the 1997 Workshop on Implementing Functional Languages | January 1997 Published by Springer Verlag\n[3] Moron Why C Is Not Assembly by James Iry (Accessed 07.04.2022)\n[4] L. Torczon and K. Cooper, Engineering A Compiler, 2nd ed. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc., 2007.\n[5] R. Nystrom, “Game Programming Patterns,” in Game Programming Patterns, Genever Benning, 2014.\n[6] G. Melchiorri, C. Castagna, R. Sorge, and M. Bonifazi, Game Scripting Mastery, vol. 24, no. 10. 2010.\n[7] R. Fabian, Data-Oriented Design: Software Engineering for Limited Resources and Short Schedules. 2018.\n[8] Introducing LuaJIT (Accessed 07.04.2022)\n[9] J. Gregory, Game Engine Architecture, Second Edition, 2nd ed. USA: A. K. Peters, Ltd., 2014.\n[10] P. S. Foundation, “Python.” https://www.python.org/ (Accessed 07.04.2022)\n[11] Mozilla, “JavaScript.” https://developer.mozilla.org/en-US/docs/Web/JavaScript (Accessed 07.04.2022)\n[12] P. S. Foundation, “Python Applications.” https://www.python.org/about/apps/ (Accessed 07.04.2022)\n[13] A. Andrade, “Game engines: a survey,” EAI Endorsed Trans. Game-Based Learn., vol. 2, no. 6, p. 150615, 2015, doi: 10.4108/eai.5-11-2015.150615\n[14] H. Muhammad and R. Ierusalimschy, “C APIs in extension and extensible languages,” J Univers. Comput. Sci., vol. 13, no. 6, pp. 839–853, 2007.\n[15] R. Ierusalimschy, L. H. De Figueiredo, and W. C. Filho, “SPE paper Lua – an extensible extension language,” vol. 6, no. 1996, pp. 635–652, 2015.\n[16] R. Ierusalimschy, L. De Figueiredo, and W. Celes, “The evolution of an extension language: A history of Lua,” Proc. V Brazilian Symp. Program. Lang., vol. 1, no. 1, pp. 1–16, 2001, [Online]. Available: [http://www.lua.org/history.html%0Ahttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.15.9210\u0026amp;rep=rep1\u0026amp;type=pdf](http://www.lua.org/history.html http:/citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.15.9210\u0026amp;rep=rep1\u0026amp;type=pdf). (Accessed 07.04.2022)\n[17] R. Ierusalimschy, L. H. de Figueiredo, and W. Celes, “Passing a Language through the Eye of a Needle,” Queue, vol. 9, no. 5, pp. 20–29, 2011, doi: 10.1145/1978862.1983083.\n","date":1654556400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654556400,"objectID":"11c7e1f564c003e7ce147ba7fd893391","permalink":"/posts/what-is-a-scripting-language/","publishdate":"2022-06-07T00:00:00+01:00","relpermalink":"/posts/what-is-a-scripting-language/","section":"posts","summary":"Have you ever stumbled upon job offers where companies are looking for \u0026ldquo;coders\u0026rdquo; or \u0026ldquo;scripters\u0026rdquo;? Every time I see those, I ask myself: what is the difference exactly? How can \u0026ldquo;scripting\u0026rdquo; or \u0026ldquo;coding\u0026rdquo; be different from programming? Is there even a difference? I could keep listing questions, but I am sure you get my point. With this in mind, I got asked a few times why I am using the term \u0026ldquo;scripting language\u0026rdquo; and \u0026ldquo;programming language\u0026rdquo; interchangeably, since they represent different concepts.","tags":["research","scripting languages"],"title":"What is a scripting language?","type":"posts"},{"authors":null,"categories":["research","gamedev"],"content":"While I was working on my Masters in Game Technology at Breda University of Applied Sciences (BUas), I came across an interesting problem: How am I executing a systematic review of GitHub repositories?\nWhen searching on the Internet, it was challenging to find good sources. I came across the fantastic work from the Department of Information and Computing Sciences, Utrecht University: A Systematic Review of Open Source Clinical Software on GitHub for Improving Software Reuse in Smart Healthcare by Zhengru Shen and Marco Spruit. They created a paper that explains step-by-step how to do a systematic review of GitHub repositories! As I mentioned in my previous blog post: \u0026ldquo;None of the standard literature regarding methodology covers this case. Okay, okay… GitHub is relatively new and special!\u0026quot;.\nYou can basically follow along and do as they described. See my previous blog post for a TL;DR version. I describe how to execute the method of collecting data a little bit more practical with a python script-based example. The example code you can find, of course, on GitHub itself: collect-data-from-github\nThis is all great but I wanted to discuss the data collection and processing part a bit more. As I found out, it is very different for each topic what kind of data you need to collect from the GitHub REST API. Also, it is important to discuss the reasoning behind the data and its processing\nTL;DR When gathering data from GitHub, we need to know in advance what we need for our study. There are 2 data sets we can collect: Textual data and numerical data. The textual data can be separated into Source Code and metadata. The metadata contains tags, topics, descriptions, README, and documentation links. The Numeric values are either date, such as the last date the project was updated, or values, such as the size of the project, the number of people staring the project issues, etc. The textual and numeric data must always be analyzed within the proper context. There are several existing tools that can help one to conduct the analyses.\nA few important takeaways about some specific data categories:\n A.I. is important to make sense out of Textual context such as README files or documentation in case manual labor shall be avoided. Such as IBM Watson Natural Language Understanding Natural Language Toolkit (NLTK) for python [9] or Google\u0026rsquo;s Natural Language A.I. [10]. Source Code analyzes can be done by tools such as static analyzes tools, documentation tools or code base visualizers. Such as Sourcetrail , Source Graph. Stars are a indication of interest in a project which needs to be set into a proper context, which can be done with tools such as RepoReaper and GHTorrent. The second meaning of stars is just to bookmark something which does not guarantee that I am actually interested in this project. Also, the risk of distortion from fake stars or promotion actions can have an influence on star growth. Commits are a not reliable source to use to calculate if a project is successful or popular when matched with stars. Due to the reason that every project has their own commit policy [14]. Forks are somewhat more reliable since there is a strong indication that they are connected with the number of stars. However, one should keep in mind that there is also the ability to have bots that do nothing else than fork projects. [14]  What kind of data can you collect on GitHub? GitHub provides a REST API [2], which is an service that allows the user to send request to it in a defined way (protocol) via the HTTP protocol and receive answers [3]. The service provides a lot of entry points, for a systematic review of GitHub Projects the search endpoint, the REST API part that is concert with searching for repositions, is very important. Besides this, there are a few other endpoints that will be very useful which are listen in Table 1.\n   Endpoint Description     Repositories \u0026ldquo;The Repos API allows access information about GitHub repositories.\u0026rdquo;   Projects \u0026ldquo;The Projects API let you fetch projects in a repository.\u0026rdquo;   Organizations \u0026ldquo;The Organizations API let you fetch information about a GitHub organizations.\u0026rdquo;    Table 1: Useful other API endpoints than the Search.\nFrom the GitHub REST API you can gather two kind of main data types: Numerical and Textual. These can be used for further analyzes. There are two different textual information you can collect on GitHub: Source Code and Meta data to describe the repository [1,2].\nThe Source Code for example can be scanned manually or via a static analyzes tool or any other tool that can understand source code and gives us a meaning full understanding of it. Alberto S.Nuñez-Varela et al., has shown in their study Source code metrics: A systematic mapping study [5] what kind of metrics can be applied when analyzing source code. The results of their work are very interesting since they report of almost 300 source code metrics. They also concluded that object oriented metrics have been mostly found and more research is needed to conduct to gather metrics for more feature oriented aspects.\nFurthermore, to analyze source code from a practical point of view. If one is looking for certain patterns, tools to visualize a codebase are useful. Sourcetrail is such an open source tool that lets you navigate through the code base virtually. An other useful tool is Source Graph which allows you to search your code and 2M+ open source repositories [6].\nThe other meta data such as README files, wiki or documentation stored in the project needs to be analyzed by hand or with the raise of AI one can make use of tools such as IBM Watson Natural Language Understanding [7] to help understand and process natural language. How you can use IBM\u0026rsquo;s Watson is greatly explained in the following article: Getting started with NLP using IBM Watson Studio by Aritro Mukherjee [8]. There are, of course, other alternatives such as Natural Language Toolkit (NLTK) for python [9] or Google\u0026rsquo;s Natural Language AI [10]. These AI driven tools can help to identify themes, topics or search for the needed information within the meta data of a repository.\nIn the space of numerical values we have also again two types: Dates and numerical values [1,4]. The dates can be used for our limitations since GitHub gives us only 3 dates [4]: pushed_at, updated_at,created_at. The meaning behind them can be described as updated_at will be updated any time the repository object is updated. A repository object is updated when one, for example, update the description or the primary language of the repository. On the other hand, pushed_at represents the date and time of the last commit. Since updated_at represents the timestamp of the last change to the repository which might be a be a commit, but it may also be other things, such as changing the description of the repo, creating wiki pages, etc. That is why one can say that commits are a subset of updates, and the pushed_at timestamp will therefore, either be the same as the updated_at timestamp, or it will be an earlier timestamp [2,11].\nThe other numeric values of interest can be gather from a GitHub Repository are described in Table 2:\n   Numeric Value Description     Stargazers \u0026ldquo;Stargazers refers to the number of times a repository is bookmarked. It reflects an approximate level of interest in the repository\u0026rdquo; [1,2]   Forks \u0026ldquo;A fork is a copy of a repository. Forking is necessary for developers to contribute a project. Forks refers to the number of forks.\u0026rdquo; [1,2]   Contributors \u0026ldquo;The number of contributors who have worked for a repository.\u0026rdquo; [1,2]   Commits \u0026ldquo;The total number of commits.\u0026rdquo; [1,2]   Issues \u0026ldquo;Issues is the number of open issues in a repository\u0026rdquo; [1,2]   Size of source codes \u0026ldquo;The size is valued as the size of the whole repository (including all of its history), in KB.\u0026rdquo; [1,2]   Size of README file \u0026ldquo;The size of the README file of a repository, in B\u0026rdquo; [1,2]    Table 2: Overview of numerical values one can gather on GitHub*\nThis data can be used and processed with methods such as GAM which are a extension of generalized linear models (GLMs), a GAM is an additive modeling technique that captures the impact of the predictive variables through smooth functions [1,2].\nThe meaning of numeric values: Stars,Forks and Commits Zhengru Shen and Marco Spruit as well as of other researchers [13,14,15] are suggesting to use stargazers (stars) as indication of popularity. Research has shown that the \u0026ldquo;stargazers-based classifier [\u0026hellip;] to exhibit high precision (97%)\u0026rdquo; when trying to find retrieving engineered software projects [16]. Munaiah, N at all Research results in \u0026ldquo;RepoReaper\u0026rdquo;. RepoReaper \u0026ldquo;is a tool used to assess a GitHub repository in the form of a score. It considers a number of different attributes in order to perform a thorough assessment.\u0026rdquo; [17] This tool is intend to be used with \u0026ldquo;together with a database of metadata provided by the GHTorrent project, reaper considers both contextual information such as commit history as well as the contents of the repository itself [17].\u0026rdquo; RepoReaper can be helpful in order to score the results of your systematic review of a subset of specific projects.\nThe Meaning of stars from a developer point of view However it is important to discuss the meaning of stars, forks, and commits. As stated by GitHub, stars are a method to keep track of projects that you find interesting or discover via the explore/ \u0026ldquo;news\u0026rdquo; feed related projects [18]. They are also frequently used by the community as bookmarks [15]. As explained in several sources, such as from Zhengru Shen and Marco Spruit and a lot of other researchers [13,14,15] ,stars have two major functions. They function as an indication that someone likes the project or that they want to book mark the project [15]. A developer on OpenSource Stackexchange states this perfectly: \u0026ldquo;[…] Users on the GitHub website are able to \u0026ldquo;star\u0026rdquo; other people\u0026rsquo;s repositories, thereby saving them in their list of Starred Repos. Some people use \u0026ldquo;stars\u0026rdquo; to indicate that they like a project, other people use them as bookmarks so they can follow what\u0026rsquo;s going on with the repo later. […]\u0026rdquo; 15, Left SE On 10_6_19].\nHudson Borges et al, provide the academic data to the statements gathered on OpenSource Stackexchange [15] in their survey of 791 developers describe how they use stars on GitHub[14]. Their Table 2 [14] shows this.\nNote: Note that one answer can receive more than one theme therefore numbers might not add up to 791 for more details see Paper.\n   Reason Total %     To show appreciation 415 52.5   Bookmarking 404 51.1   Due to usage 290 36.7   Due to recommendations 36 4.6   Unknown reasons 5 0.6    Table 3. Why do users star GitHub repositories? (95% confidence level with a 3.15% confidence interval). based on Table 2 from \u0026ldquo;What’s in a GitHub Star? Understanding Repository Starring Practices in a Social Coding Platform\u0026rdquo; by Hudson Borges at al.\nThe reason why one needs to look at stars critical is that from technical perspective they are simple to fake. Since it is very simple to just create GitHub fake accounts and write a bot that just likes your project [15]. Besides the simplicity of faking stars a huge growth of stars might be the result of a promotion on social media (e.g. twitter) [13]. Hudson Borges at al suggests that \u0026ldquo;when ranking projects, we should check whether stars are result of active promotion\u0026rdquo; in their recommendations for researchers at the end of their journal article [15]. There are two main reasons why we should look critically on stars. Firstly one is that they might be created through fake accounts. Secondly they might be a result of active promotion on social media platforms.\nMoreover Hudson Borges et al, suggested in their final conclusion that stars are important for users to pick a project. The study found out that 3 out of 4 developers (of the 791 developers surveyed developers) check the stars metric before using or contributing to projects. Despite this strong indication between stars and popularity, the paper suggested that other factors such as code quality and documentation are important. Both factors can be evaluated with RepoReaper in order to create a relationship between popularity and documentation / code quality [16,17]. For a lot of developers stars are a great indication to either contribute to a project but not just other factors such as code quality and documentation necessary.\nForks and commits Research has shown that forks can be used to evaluate the popularity of a project since there is a strong correlation between stars and forks [15]. It is noteworthy to say that there are fork bots out there that just fork a project automatically since this can also be done automatic via the REST API [2]. That bots may create forks of projects might be important to consider when using the fork value as a indication for popularity. Forking a project via bots is not that frequently done as for stars that this can be ignored but still it is important to keep this in mind when building an argumentation about the correlation between stars and forks.\nCommits however only show a weak correlation with stars [15]. This can be explained with the practical reason that the way a project handles its commits can differ greatly, since every bigger project has their own policies in regards to how often one shall commit and how big they shall be. For example, The QT project has its own policies Commit Policy or the KDE Projects Policies/Commit Policy. Looking at this from a developer point of view, it explains than that the number of commits in relation to stars or in general towards the project popularity cannot be a hard link. The main indication of commits is to show how actively maintained a project is. Every commit will change the pushed_at date. The fact that every project might have their own commit policy explains why the number of commits and the projects popularity has just a weak link.\nTakeaways The main takeaways are that when one is analyzing GitHub repositories, one has to take the different limiting factors into account. These limiting factors are sometimes better described by users of GitHub than by pure academia. The best example is the discussion on Opensource Stack Exchange \u0026ldquo;GitHub Stars\u0026rdquo; is a very useful metric. But for what? from Left SE On 10_6_19. Moreover, it is important to realize what is the meaning behind the possible metrics. There has been some great work done by several authors [1,5,13,16]. Therefore it can be said that:\n A.I. is important to make sense out of Textual context such as README files or documentation in case manual labor shall be avoided. Such as IBM Watson Natural Language Understanding Natural Language Toolkit (NLTK) for python [9] or Google\u0026rsquo;s Natural Language A.I. [10]. Source Code analyzes can be done by tools such as static analyzes tools, documentation tools or code base visualizers. Such as Sourcetrail , Source Graph. Stars are a indication of interest in a project which needs to be set into a proper context, which can be done with tools such as RepoReaper and GHTorrent. The second meaning of stars is just to bookmark something which does not guarantee that I am actually interested in this project. Also, the risk of distortion from fake stars or promotion actions can have an influence on star growth. Commits are a not reliable source to use to calculate if a project is successful or popular when matched with stars. Due to the reason that every project has their own commit policy [14]. Forks are somewhat more reliable since there is a strong indication that they are connected with the number of stars. However, one should keep in mind that there is also the ability to have bots that do nothing else than fork projects. [14]  References [1] Department of Information and Computing Sciences, Utrecht University: A Systematic Review of Open Source Clinical Software on GitHub for Improving Software Reuse in Smart Healthcare by Zhengru Shen and Marco Spruit\n[2] GitHub REST API (accessed on 02 April 2022).\n[3] What is a REST API? (accessed on 02 April 2022).\n[4] GitHub Repositories (accessed on 02 April 2022).\n[5] Alberto S. Nuñez-Varela, Héctor G. Pérez-Gonzalez, Francisco E. Martínez-Perez, Carlos Soubervielle-Montalvo, Source code metrics: A systematic mapping study, Journal of Systems and Software, Volume 128, 2017 https://doi.org/10.1016/j.jss.2017.03.044.\n[6] Source Graph (accessed on 02 April 2022).\n[7] BM Watson Natural Language Understanding. Available online: https://www.ibm.com/cloud/watson-natural-language-understanding (accessed on 02 April 2022).\n[8] Getting started with NLP using IBM Watson Studio by Aritro Mukherjee (accessed on 02 April 2022)\n[9] Natural Language Toolkit (NLTK) (access on 02 April 2022)\n[10] Google\u0026rsquo;s Natural Language AI (access on 02 April 2022)\n[11] Difference between “updated_at” and “pushed_at” in repositories list response (access on 02 April 2022)\n[12] Wood, S.N. Generalized Additive Models: An Introduction with R; Chapman and Hall/CRC: London, UK, 2006.\n[13] Characterizing and predicting the popularity of github projects by Hudson Silva Borges https://repositorio.ufmg.br/handle/1843/BIRC-BBLN2S (access on 02 April 2022)\n[14] Hudson Borges, Marco Tulio Valente, What’s in a GitHub Star? Understanding Repository Starring Practices in a Social Coding Platform, Journal of Systems and Software,Volume 146, 2018, Pages 112-129, ISSN 0164-1212, https://doi.org/10.1016/j.jss.2018.09.016.\n[15] \u0026ldquo;GitHub Stars\u0026rdquo; is a very useful metric. But for what? asked by Left SE On 10_6_19 on opensource.stackexchange.com (access on 02 April 2022)\n[16] Munaiah, N., Kroh, S., Cabrey, C. et al. Empir Software Eng (2017) 22: 3219. https://doi.org/10.1007/s10664-017-9512-6\n[17] RepoReaper (access on 02 April 2022)\n[18] Saving repositories with stars (access on 02 April 2022)\n","date":1649113200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649113200,"objectID":"7133cf95a5c10ca23873501c026c3230","permalink":"/posts/systematic_review_on_github_method_discussion/","publishdate":"2022-04-05T00:00:00+01:00","relpermalink":"/posts/systematic_review_on_github_method_discussion/","section":"posts","summary":"When conducting a systematic review on GitHub its important to realize that you need to know the data. When gathering data from GitHub, we need to know in advance what we need for our study. There are 2 data sets we can collect: Textual data and numerical data. Also there are great tools out there that can help us...","tags":["research","github","research method"],"title":"GitHub Systematic Review: Know your data.","type":"posts"},{"authors":null,"categories":["research","gamedev"],"content":"While I was working on my Masters in Game Technology at Breda University of Applied Sciences (BUas), I came across an interesting problem: How am I executing a systematic review of GitHub repositories?\nNone of the standard literature regarding methodology covers this case. Okay okay\u0026hellip; GitHub is relatively new and special!\nThe lack of answers in literature led me into the wild of the Internet. Sadly when googling \u0026lsquo;Systematic Review of GitHub Repositories\u0026rsquo;, you do not find a \u0026ldquo;HowTo\u0026rdquo; or actually a good GitHub repository with some software.\nThat I find little on regular Google is interesting because Google Scholar gives you a lot of entries when looking for Reviews on GitHub. Sadly, many of these reviews are, as per usual, behind a paywall. Moreover, those papers usually just claim, \u0026ldquo;We did this \u0026hellip; description,\u0026rdquo; but there is seldom any code to be found, or if there is code, it is written in some obscure language an average Game Developer does not use\u0026hellip;\nWell, I just adjusted my search a bit. Finally, I came across this fantastic article from the Department of Information and Computing Sciences, Utrecht University: A Systematic Review of Open Source Clinical Software on GitHub for Improving Software Reuse in Smart Healthcare by Zhengru Shen and Marco Spruit. They did a fantastic job by creating a paper that explains step-by-step how to do a systematic review of GitHub repositories!\nLet me give you a TL;DR (for more details, you need to read my paper later or the original paper link above):\nData Extraction\n  We do a preliminary search of our topic with some keywords or topics of our liking by using GitHub Search and GitHub Topics.\n  We try this in multiple languages to find the correct language (I am talking about natural languages such as English). Maybe our specific topic is more common in Spanish than English, or we need to analyze both. This is important to know.\n  Might we already have a time frame based on our literature review? This is important to take into account when searching for anything on GitHub.\n  We also need to decide: Are the Programming Languages important or not? In general, what is needed from this search for our data analysis? For this, I recommend opening the REST API\u0026rsquo;s reference manual: GitHub search REST API. This has a list of things you can extract.\n4.1 Do I need some extra information besides the repository? Or the byte size usage is essential? If yes, check the rest of the API\u0026rsquo;s documentation. Check out the API\u0026rsquo;s Reference\n  We connect to the GitHub search REST API with our python script using a token: How to use a token to authentify? We are using Python and PyGitHub, which does most of the work for us.\n  We can define multiple queries for the search, if needed for your topic. GitHub allows you to search besides regular queries such as \u0026ldquo;scripting languages\u0026rdquo; also for topics: \u0026ldquo;topic:scripting-languages\u0026quot;. Using topic queries besides regular queries may increase the results of your search. Moreover, you can exclude things. For example, if you wanted to exclude all Visual Studio Extensions from your search, all you need to do is: \u0026ldquo;scripting languages NOT Visual+Studio\u0026rdquo; (The + is important because otherwise, it will ignore only \u0026ldquo;Visual\u0026rdquo; and not \u0026ldquo;Visual Studio\u0026quot;). For more info about the search syntax check: Understanding the search syntax\n  After the last step, you need to store the findings in some form. For example, you can keep your results in a CSV file or in a database.\n  Data Processing\nThis is where my TL;DR ends since this highly depends on your topic. For example, you can do a Descriptive Analysis, an example of which can be found in the original paper. You can also use Generalized Additive Models to process the data. Moreover, you might need an AI to analyze all the README files, descriptions, etc., to extract the extra data you need. Zhengru Shen and Marco Spruit are using Watson to do some of their topic modelings (see 2.4. Topic Modeling).\nAnyways, as a game dev (or a game dev to be), I love sample code and practical things! This is why I really like the paper I mentioned before since the authors also provided the GitHub repository with the source code of the used code for their study. From an academic point of view, this delights my heart since I could reproduce their paper. The developer in me is happy since I have a script example for my paper! The original source code you can find here: ianshan0915/clinical-opensource-projects (a collection of python scripts).\n Warning: This repository is not made to be reused to be used for your own project. You can (like I did), but you still need to read the source code and find things you do not need. As I said, I love, absolutely love sample code! This is what this code is for.\n What does this repo contain? Before we open the GitHub repo and clone it, let\u0026rsquo;s have a look at how they describe it in their paper:\n\u0026ldquo;The data extraction pipeline was written in Python using a third-party library, PyGitHub. The pipeline took the chosen search terms as input and received repository data in JSON. The JSON responses were first filtered and then converted to database records and pushed to tables in a MySQL database. Repositories with no description or no programming language specified were excluded from further analysis for the reason that clinical software was the focus of our study. The whole process is reproducible by running the Python scripts at Reference [22]. Moreover, replacing the search term with others scales the pipeline to other domains.\u0026rdquo; (22: Source Codes of Open Source Clinical Software. Available online: https://github.com/ianshan0915/clinical- opensource-projects (accessed on 25 November 2018)) A Systematic Review of Open Source Clinical Software on GitHub for Improving Software Reuse in Smart Healthcare\nAfter reading the description of their data extraction pipeline, we open the repo. However, there are no instructions on how to use/install the scripts in the README. But no worries, I have a quick summary of what you need:\n PyGitHub communication with the GitHub REST API pandas Watson Developer Cloud Python SDK for analysing the readme files and descriptions textrazor  The conclusion for me is it is excellent that I have the code, but I would spend too much time bending it to my will. I can better follow their lead and write my own script, which is something I think all game devs know somehow.\nMy take on it\nNow, this is what I did, and I ended up with a small Python script that can be used for my purposes. If you need just data collection from GitHub, you can also use it: GitHub search query python\nThe script allows you to write a simple configuration JSON file:\n{ \u0026quot;token\u0026quot;: \u0026quot;my token\u0026quot;, \u0026quot;readme_dir\u0026quot;: \u0026quot;./\u0026quot;, \u0026quot;output\u0026quot;: \u0026quot;./\u0026quot;, \u0026quot;format\u0026quot;: \u0026quot;CSV\u0026quot;, \u0026quot;criteria\u0026quot;: { \u0026quot;time\u0026quot;: { \u0026quot;min\u0026quot;: 2010, \u0026quot;max\u0026quot;: 2022 } }, \u0026quot;terms\u0026quot;: [ \u0026quot;MY SEARCH QUERY\u0026quot;, \u0026quot;MY SEARCH QUERY\u0026quot;, ], \u0026quot;attrs\u0026quot;: [ \u0026quot;id\u0026quot;, \u0026quot;full_name\u0026quot;, ] }  To communicate with the GitHub API, you need a token you can obtain via your GitHub account. This field is optional, and you can also pass it as an argument to the script if you prefer this! As of writing, you have an hourly request rate of 5000 requests. Besides, the script obeys some cooldown time in between requests to not be locked out by the DDOS security of the API. The output field lets you define where your collected data shall be stored. The file name will be repositories_DATE.[csv,json] since I decided to spill out a CSV or JSON file, you can parse it later if you need to. If you need to download README files, you also provide a readme_dir field. They will be stored in there by repo + date. If it is not present, the script assumes you do not need them. The criteria take the time frame from when to when do you need this, which will be used to collect repositories within the defined time frame. The heart of your config is a list of the terms you are searching for:\n\u0026quot;terms\u0026quot;: [ \u0026quot;topic:visual-scripting-language NOT Visual+Studio\u0026quot;, \u0026quot;topic:visual-programming-language NOT Visual+Studio\u0026quot;, \u0026quot;topic:visual-programming NOT Visual+Studio\u0026quot;, \u0026quot;topic:visual-scripting NOT Visual+Studio\u0026quot;, \u0026quot;topic:visual-programming-editor NOT Visual+Studio\u0026quot;, \u0026quot;topic:dataflow-programming NOT Visual+Studio\u0026quot; ],  This will execute the criteria for those search terms every time!\nLast but not least, we have attrs that allow you to define the fields you care about from the REST API repository. There is more info on what to write in there: GitHub search REST API\nNow you might wonder how to actually run this script:\npython github-search-query.py --help  The previous command will give you some ideas on how to run it. But there is a faster way:\npython github-search-query.py config.json  And if you want to pass a token along:\npython github-search-query.py --token my_token config.json  Well that\u0026rsquo;s pretty much it! Have fun data collecting!\n","date":1640646000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640646000,"objectID":"2fb13d2cabc126a9290dda1227c515a4","permalink":"/posts/systematic_review_on_github/","publishdate":"2021-12-28T00:00:00+01:00","relpermalink":"/posts/systematic_review_on_github/","section":"posts","summary":"While I was working on my Masters in Game Technology at Breda University of Applied Sciences (BUas), I came across an interesting problem: How am I executing a systematic review of GitHub repositories?\nNone of the standard literature regarding methodology covers this case. Okay okay\u0026hellip; GitHub is relatively new and special!\nThe lack of answers in literature led me into the wild of the Internet. Sadly when googling \u0026lsquo;Systematic Review of GitHub Repositories\u0026rsquo;, you do not find a \u0026ldquo;HowTo\u0026rdquo; or actually a good GitHub repository with some software.","tags":["research","github","python","research method"],"title":"Systematic review of repositories on GitHub with python (Game Dev Style)","type":"posts"},{"authors":null,"categories":["lecture","cpp","gamedev"],"content":" This is a workshop created for Breda University of Applied Sciences 2021 with the original title: C++ Compilation process Workshop 2021\n In this workshop / how to you learn how the C++ Compilation process works in a nutshell. Before you can start you need to do some form of preps as described in the next step.\nPreparations In order to participate you need to install the right compiler and linker.\nWindows\nIf we have Visual Studio 19/22 installed with the C++ extensions or VS Code with the C++ tooling we have our linker and compiler installed.\n Note: How to use the compiler from the command line follow this guide https://docs.microsoft.com/en-us/cpp/build/building-on-the-command-line?view=msvc-170\n Linux Debain/Ubuntu\nOn Linux we need to install the basic build essentials. This includes the default compiler (usually GCC GNU C Compiler) and the linker\n Note: if you want to use the WSL follow these instructions https://docs.microsoft.com/en-us/windows/wsl/install and than use the windows store / Microsoft store and download Ubuntu or Debian\n Install (gcc):\nsudo apt update sudo apt install build-essential gcc --version  Install (clang)\nsudo apt update sudo apt install clang clang --version  Overview The C/C++ compilation process takes one source file at the time and creates a Translation unit of them. Individually they do not now anything of each other! The linker will combine them at the end.\nThe compilation process of a translation unit (TU) looks as following:\n Source files are cleaned We parse the file and run the pre-processor  each introduced include goes into step 1 All pre-processor directives are removed from the source.   Literal strings and characters are translated Compilation takes place of tokens: translation units Template instanton happens instantiation units Linking   Note: Some compilers don\u0026rsquo;t implement instantiation units (also known as template repositories or template registries) and simply compile each template instantiation at Phase 7 (4), storing the code in the object file where it is implicitly or explicitly requested, and then the linker collapses these compiled instantiations into one at Phase 9 (6). (https://en.cppreference.com/w/cpp/language/translation_phases)\n Pre-processor Did we not forget the pre-processor?\n#define value 1 // I am a comment int main(){ int var{value}; }  If we now compile this we can store the pre processor output in a file:\nWindows\ncl.exe /c /P preprocessor.cpp  Linux\ngcc preprocessor.cpp -E\u0026gt;preprocessor.i clang preprocessor.cpp -E\u0026gt;preprocessor.i  We now see a file names: preprocessor.i :\n#line 1 \u0026quot;preprocessor.cpp\u0026quot; int main(){ int var{1}; }  The line int var{value}; has been changed to int var{1}; and the #define value 1 was erased! Also the comment was removed!\nInclusion If you include any header file the pre processor will include them recursively.\nheaderA.hpp struct StructA{}; headerB.hpp #include \u0026quot;headerA.hpp\u0026quot; struct StructB{}; source.cpp #include \u0026quot;headerB.hpp\u0026quot; int main(){ StructA struct_a{}; }  If we now compile this we can store the pre processor output in a file:\nWindows\ncl.exe /c /P source.cpp  Linux\ngcc preprocessor.cpp -E\u0026gt;preprocessor.i clang preprocessor.cpp -E\u0026gt;preprocessor.i  We now see a file names: source.i or linux:\n# 1 \u0026quot;preprocessor/source.cpp\u0026quot; # 1 \u0026quot;\u0026lt;built-in\u0026gt;\u0026quot; 1 # 1 \u0026quot;\u0026lt;built-in\u0026gt;\u0026quot; 3 # 383 \u0026quot;\u0026lt;built-in\u0026gt;\u0026quot; 3 # 1 \u0026quot;\u0026lt;command line\u0026gt;\u0026quot; 1 # 1 \u0026quot;\u0026lt;built-in\u0026gt;\u0026quot; 2 # 1 \u0026quot;preprocessor/source.cpp\u0026quot; 2 # 1 \u0026quot;preprocessor/headerB.hpp\u0026quot; 1 # 1 \u0026quot;preprocessor/headerA.hpp\u0026quot; 1 struct StructA{}; # 2 \u0026quot;preprocessor/headerB.hpp\u0026quot; 2 struct StructB{}; # 2 \u0026quot;preprocessor/source.cpp\u0026quot; 2 int main(){ StructA struct_a{}; }  Header Guards As you could see Includes are recursive this can lead to cycle includes.\ncycleA.hpp #include \u0026quot;cycleB.hpp\u0026quot; cycleB.hpp #include \u0026quot;cycleA.hpp\u0026quot;  if we now compile this with (clang, gcc, msvc)\nWindows\ncl.exe /c /P cycleA.cpp  Linux\nclang cycleA.hpp -E\u0026gt;cycleA.i gcc cycleA.hpp -E\u0026gt;cycleA.i  Result will be:\nuser@MININT-DAH9RK3:/mnt/d/cpplecture$ clang cycleA.hpp -E\u0026gt;preprocessor.i In file included from preprocessor/cycleA.hpp:1: In file included from preprocessor/cycleB.hpp:1: In file included from preprocessor/cycleA.hpp:1: [edit by Simon replaced 200 more of `In file included from preprocessor/cycleA.hpp:1:` with this line] preprocessor/cycleB.hpp:1:10: error: #include nested too deeply #include \u0026quot;cycleA.hpp\u0026quot;  if we add now a #pragma once to cycleB.hpp\n#pragma once #include \u0026quot;cycleA.hpp\u0026quot;  the compiler (clang, gcc, msvc) will run and spill out:\nWindows\ncl.exe /c /P cycleA.cpp  Linux\nclang cycleA.hpp -E\u0026gt;cycleA.i gcc cycleA.hpp -E\u0026gt;cycleA.i  The result:\n# 1 \u0026quot;preprocessor/cycleA.hpp\u0026quot; # 1 \u0026quot;\u0026lt;built-in\u0026gt;\u0026quot; 1 # 1 \u0026quot;\u0026lt;built-in\u0026gt;\u0026quot; 3 # 383 \u0026quot;\u0026lt;built-in\u0026gt;\u0026quot; 3 # 1 \u0026quot;\u0026lt;command line\u0026gt;\u0026quot; 1 # 1 \u0026quot;\u0026lt;built-in\u0026gt;\u0026quot; 2 # 1 \u0026quot;preprocessor/cycleA.hpp\u0026quot; 2 # 1 \u0026quot;preprocessor/cycleB.hpp\u0026quot; 1 # 1 \u0026quot;preprocessor/cycleA.hpp\u0026quot; 1 # 2 \u0026quot;preprocessor/cycleB.hpp\u0026quot; 2 # 1 \u0026quot;preprocessor/cycleA.hpp\u0026quot; 2  Compile a source file The basic source file:\nint main(){}  Invoke the compiler:\nWindows\ncl.exe /c empty.cpp  Linux\nclang -c empty.cpp gcc -c empty.cpp  This generates a object file. .obj or .o on linux.\nAssembler This way we skipped one step: The assembler! This is the step in which the compiler creates a assembly representation for your target platform!\nTo get the output that is used to generate the Object File you must tell the compiler to generate the assemble output for you:\nWindows\ncl.exe /FAs /c empty.cpp  This will produce as .asm file with your assembly\nLinux\nclang -S  This will produce a .s file with your assembly.\nInspecting a object file Normally the compiler does the assembler step automatically and generates the object file. A object file contains all important information about the current translation unit. The most important question is: Which external objects are references? This is important since a TU does not know anything about other TU\u0026rsquo;s! The linker needs this information later to stitch the program together!\n Note: A Object file is on windows and Linux Systems different. Since on Windows it is a COFF generated by Microsoft C compiler and on Linux ELF/DWARF.\n https://en.wikipedia.org/wiki/COFF https://en.wikipedia.org/wiki/Executable_and_Linkable_Format   We can view a Object file with:\nWindows\nMore infos: https://docs.microsoft.com/en-us/cpp/build/reference/dumpbin-options?view=msvc-170\nDUMPBIN.EXE /ALL empty.obj  Linux\nobjectdump -a empty.o   Note: There could be a entire lecture about this! https://www.youtube.com/watch?v=a5L66zguFe4\n Linker In this stage of the process multiple object files will be combined to a executable!\nExecutable Lets build a game:\n/game/main.cpp /lib/engine.hpp /lib/engine.cpp main.cpp #include \u0026quot;engine.hpp\u0026quot; int main(){ engine{create()}; } engine.hpp struct engine{ // stuff }; [[nodiscard]] engine create() noexcept; engine.cpp #include \u0026quot;engine.hpp\u0026quot; [[nodiscard]] engine create() noexcept{ return {}; }  Let us compile the game:\nWindows\ncd /game cl.exe \\c main.cpp  Linux\ncd /game clang -c main.cpp -std=c++17 gcc -c main.cpp -std=c++17  This will spill out a compile error!\nPS D:\\cpplecture\\linker\\game\u0026gt; cl.exe /c main.cpp Microsoft (R) C/C++ Optimizing Compiler Version 19.29.30136 for x86 Copyright (C) Microsoft Corporation. All rights reserved. main.cpp main.cpp(1): fatal error C1083: Cannot open include file: 'engine.hpp': No such file or directory   Note: On Linux we will have the same result!\n We need to tell the compiler where the header file is! /I[..] or -I[..]\nPS D:\\cpplecture\\linker\\game\u0026gt; cl.exe /c main.cpp /I ../lib  This works! we have a obj file!\nLet us investigate what is in the object file: We run DUMPBIN.EXE /ALL main.obj\nPS D:\\cpplecture\\linker\\game\u0026gt; DUMPBIN.EXE /ALL main.obj Microsoft (R) COFF/PE Dumper Version 14.29.30136.0 Copyright (C) Microsoft Corporation. All rights reserved. Dump of file main.obj File Type: COFF OBJECT FILE HEADER VALUES 14C machine (x86) 4 number of sections 61A8E6C9 time date stamp Thu Dec 2 16:31:21 2021 193 file pointer to symbol table D number of symbols 0 size of optional header 0 characteristics SECTION HEADER #1 .drectve name 0 physical address 0 virtual address 2F size of raw data B4 file pointer to raw data (000000B4 to 000000E2) 0 file pointer to relocation table 0 file pointer to line numbers 0 number of relocations 0 number of line numbers 100A00 flags Info Remove 1 byte align RAW DATA #1 00000000: 20 20 20 2F 44 45 46 41 55 4C 54 4C 49 42 3A 22 /DEFAULTLIB:\u0026quot; 00000010: 4C 49 42 43 4D 54 22 20 2F 44 45 46 41 55 4C 54 LIBCMT\u0026quot; /DEFAULT 00000020: 4C 49 42 3A 22 4F 4C 44 4E 41 4D 45 53 22 20 LIB:\u0026quot;OLDNAMES\u0026quot; Linker Directives ----------------- /DEFAULTLIB:LIBCMT /DEFAULTLIB:OLDNAMES SECTION HEADER #2 .debug$S name 0 physical address 0 virtual address 74 size of raw data E3 file pointer to raw data (000000E3 to 00000156) 0 file pointer to relocation table 0 file pointer to line numbers 0 number of relocations 0 number of line numbers 42100040 flags Initialized Data Discardable 1 byte align Read Only RAW DATA #2 00000000: 04 00 00 00 F1 00 00 00 67 00 00 00 29 00 01 11 ....ñ...g...)... 00000010: 00 00 00 00 44 3A 5C 63 70 70 6C 65 63 74 75 72 ....D:\\cpplectur 00000020: 65 5C 6C 69 6E 6B 65 72 5C 67 61 6D 65 5C 6D 61 e\\linker\\game\\ma 00000030: 69 6E 2E 6F 62 6A 00 3A 00 3C 11 01 22 00 00 07 in.obj.:.\u0026lt;..\u0026quot;... 00000040: 00 13 00 1D 00 B8 75 00 00 13 00 1D 00 B8 75 00 .....¸u......¸u. 00000050: 00 4D 69 63 72 6F 73 6F 66 74 20 28 52 29 20 4F .Microsoft (R) O 00000060: 70 74 69 6D 69 7A 69 6E 67 20 43 6F 6D 70 69 6C ptimizing Compil 00000070: 65 72 00 00 er.. SECTION HEADER #3 .text$mn name 0 physical address 0 virtual address 12 size of raw data 157 file pointer to raw data (00000157 to 00000168) 169 file pointer to relocation table 0 file pointer to line numbers 1 number of relocations 0 number of line numbers 60500020 flags Code 16 byte align Execute Read RAW DATA #3 00000000: 55 8B EC 51 E8 00 00 00 00 88 45 FF 33 C0 8B E5 U.ìQè.....Eÿ3À.å 00000010: 5D C3 ]Ã RELOCATIONS #3 Symbol Symbol Offset Type Applied To Index Name -------- ---------------- ----------------- -------- ------ 00000005 REL32 00000000 9 ?create@@YA?AUengine@@XZ (struct engine __cdecl create(void)) SECTION HEADER #4 .chks64 name 0 physical address 0 virtual address 20 size of raw data 173 file pointer to raw data (00000173 to 00000192) 0 file pointer to relocation table 0 file pointer to line numbers 0 number of relocations 0 number of line numbers A00 flags Info Remove (no align specified) RAW DATA #4 00000000: 23 07 66 15 27 1A BF 1A FD FD 6A 15 8D E6 A5 E2 #.f.'.¿.ýýj..æ¥â 00000010: 42 E8 D5 96 AB C2 64 E1 00 00 00 00 00 00 00 00 BèÕ.«Âdá........ COFF SYMBOL TABLE 000 010575B8 ABS notype Static | @comp.id 001 80010191 ABS notype Static | @feat.00 002 00000002 ABS notype Static | @vol.md 003 00000000 SECT1 notype Static | .drectve Section length 2F, #relocs 0, #linenums 0, checksum 0 005 00000000 SECT2 notype Static | .debug$S Section length 74, #relocs 0, #linenums 0, checksum 0 007 00000000 SECT3 notype Static | .text$mn Section length 12, #relocs 1, #linenums 0, checksum 6BED4AA5 009 00000000 UNDEF notype () External | ?create@@YA?AUengine@@XZ (struct engine __cdecl create(void)) 00A 00000000 SECT3 notype () External | _main 00B 00000000 SECT4 notype Static | .chks64 Section length 20, #relocs 0, #linenums 0, checksum 0 String Table Size = 0x1D bytes Summary 20 .chks64 74 .debug$S 2F .drectve 12 .text$mn  Under RELOCATIONS #3 we find something intersting:\n Symbol Symbol Offset Type Applied To Index Name 00000005 REL32 00000000 9 ?create@@YA?AUengine@@XZ (struct engine __cdecl create(void))  This somehow looks like: [[nodiscard ]] engine create() noexcept. That is correct! In C++ we mangle names we (the compiler) renames the name after they implementation defined scheme (yes clang uses a different method than msvc! GREAT!)\n The reason for this is that we can have overloads (in short!) more infos here https://www.geeksforgeeks.org/extern-c-in-c/\n This means the compiler stores in the object file all sorts of interesting information about this TU (translation unit). In this case the compiler stores that at a offset of 5 the symbol ?create@@YA?AUengine@@XZ (struct engine __cdecl create(void)) needs to be relocated! Relocated means that it can be found external!\nEnough of this inspection lets us create our executable!\nPS D:\\cpplecture\\linker\\game\u0026gt; link.exe main.obj  This also leads to a error!\nMicrosoft (R) Incremental Linker Version 14.29.30136.0 Copyright (C) Microsoft Corporation. All rights reserved. main.obj : error LNK2019: unresolved external symbol \u0026quot;struct engine __cdecl create(void)\u0026quot; (?create@@YA?AUengine@@XZ) referenced in function _main main.exe : fatal error LNK1120: 1 unresolved externals  Do we remember:\n This means the compiler stores in the object file all sorts of interesting information about this TU (translation unit). In this case the compiler stores that at a offset of 5 the symbol ?create@@YA?AUengine@@XZ (struct engine __cdecl create(void)) needs to be relocated! Relocated means that it can be found external!\n This is what it means in practice! Oh right we did not compile lib/engine.cpp Let us fix this!\nPS D:\\cpplecture\\linker\\game\u0026gt; cd .. PS D:\\cpplecture\\linker\u0026gt; cd lib PS D:\\cpplecture\\linker\\lib\u0026gt; cl.exe /c engine.cpp  Now we have a lib/engine.obj\ncool lets go back to our game and try again!\nPS D:\\cpplecture\\linker\\game\u0026gt; link.exe main.obj Microsoft (R) Incremental Linker Version 14.29.30136.0 Copyright (C) Microsoft Corporation. All rights reserved. main.obj : error LNK2019: unresolved external symbol \u0026quot;struct engine __cdecl create(void)\u0026quot; (?create@@YA?AUengine@@XZ) referenced in function _main main.exe : fatal error LNK1120: 1 unresolved externals  We get the same error! But we compiled the other thing\u0026hellip;\nThis time we have to remmeber:\n Translation Units are looked at individually and main.obj does not know anything of engine.obj!\n This means we need to tell the linker where our external symbols are living!\nPS D:\\cpplecture\\linker\\game\u0026gt; link.exe main.obj ../lib/engine.obj  This works we get out executable!\nLibrary In reality projects are really big and sometimes we split them into libraries. In general a library is nothing else than a collection of object files the linker can use statically or dynamically!\n Note: This overview will not touch the dynamic approach since this is a huge topic on its own!\n Lets upgrade our \u0026ldquo;engine\u0026rdquo; example a bit:\nengine.hpp #pragma once using cstring = const char*; template\u0026lt;typename T\u0026gt; struct container_t{ T* items; unsigned int num_items; unsigned int capacity; }; struct entity_t { unsigned int id; }; struct world_t{ container_t\u0026lt;entity_t\u0026gt; entities; }; struct engine_t{ void update(double dt); entity_t spawn(); world_t world; }; [[nodiscard ]] engine_t create() noexcept; #include \u0026quot;engine.hpp\u0026quot; [[nodiscard]] engine_t create() noexcept{ engine_t e{}; e.world.entities.items = new entity_t[100]; e.world.entities.capacity = 100; return e; } entity_t engine_t::spawn(){ if(world.entities.num_items == world.entities.capacity){ // magic }else{ world.entities.items[world.entities.num_items] = {world.entities.num_items}; } return {world.entities.num_items}; } void engine_t::update(double dt){ //... }  Let us add a json parser \u0026hellip; every good C++ project needs one!\njson.hpp #pragma once using cstring = const char*; struct string_view{ cstring data_ptr; unsigned int len; }; struct json{ //.. }; struct json_object{ //.. }; struct json_array{ json_object* objects; unsigned int len; }; [[nodiscard]] json parse(cstring path) noexcept; [[nodiscard]] json_object get_object(const json\u0026amp; root,cstring key) noexcept; [[nodiscard]] json_array get_array(const json\u0026amp; root,cstring key) noexcept; [[nodiscard]] string_view get_string(const json\u0026amp; root,cstring key) noexcept; [[nodiscard]] double get_number(const json\u0026amp; root,cstring key) noexcept; #include \u0026quot;json.hpp\u0026quot; [[nodiscard]] json parse(cstring path) noexcept{ return {}; } [[nodiscard]] json_object get_object(const json\u0026amp; root,cstring key) noexcept{ return {}; } [[nodiscard]] json_array get_array(const json\u0026amp; root,cstring key) noexcept{ return {}; } [[nodiscard]] string_view get_string(const json\u0026amp; root,cstring key) noexcept{ return {}; } [[nodiscard]] double get_number(const json\u0026amp; root,cstring key) noexcept{ return {}; }  The game:\nlevel.hpp #include \u0026quot;engine.hpp\u0026quot; struct level{ world_t world; }; void load(engine_t\u0026amp; engine, cstring level) noexcept; level.cpp #include \u0026quot;engine.hpp\u0026quot; #include \u0026quot;json.hpp\u0026quot; void load(engine_t\u0026amp; engine, cstring level) noexcept{ json l{parse(level)}; } main.cpp #include \u0026quot;engine.hpp\u0026quot; #include \u0026quot;level.hpp\u0026quot; int main(){ engine_t core{create()}; load(core,\u0026quot;Test_level.json\u0026quot;); }  Let us build a .lib or .a file.\n Note: again a static lib is nothing else than a collection (or archive) or object files. This is why the name on Linux is .a which stands for archive and the tool on Linux for creating one is called ar https://linux.die.net/man/1/ar\n At first we need to compile both of our translation units (source files):\nWindows\ncd lib PS D:\\cpplecture\\linker\\lib\u0026gt; cl.exe /c engine.cpp json.cpp --\u0026gt; engine.obj --\u0026gt; json.obj  Linux\nclang -c engine.cpp json.cpp -std=c++17 gcc -c engine.cpp json.cpp -std=c++17 --\u0026gt; json.o --\u0026gt; engine.o  Now we need to stich those object files together this can be done via the lib.exe or the ar tool on linux:\nWindows\nlib.exe .\\json.obj .\\engine.obj /out:engine.lib   https://docs.microsoft.com/en-us/cpp/build/reference/overview-of-lib?view=msvc-170\n Linux\nar rc engine.a json.o engine.o   https://llvm.org/docs/CommandGuide/llvm-ar.html or https://linux.die.net/man/1/ar\n Now we have a lib: engine.lib or engine.a and we can now link against this with ld (on Linux) or link.exe on windows just like we were to link object files:\nWindows\n cl.exe main.cpp level.cpp /c /I ../lib link.exe .\\main.obj .\\level.obj ../lib/engine.lib /out:game.exe --\u0026gt; game.exe  Linux\nclang main.cpp level.cpp -c -I ../lib ld .\\main.o .\\level.o ../lib/engine.a -o game --\u0026gt; game  Extra If we now inspect the engine.obj\nPS D:\\cpplecture\\linker\\game\u0026gt; DUMPBIN.EXE /RELOCATIONS engine.lib Microsoft (R) COFF/PE Dumper Version 14.29.30136.0 Copyright (C) Microsoft Corporation. All rights reserved. Dump of file engine.lib File Type: LIBRARY RELOCATIONS #3 Symbol Symbol Offset Type Applied To Index Name -------- ---------------- ----------------- -------- ------ 00000077 REL32 00000000 9 ??_U@YAPAXI@Z (void * __cdecl operator new[](unsigned int))  and for main.obj\nPS D:\\cpplecture\\linker\\game\u0026gt; DUMPBIN.EXE /RELOCATIONS main.obj Microsoft (R) COFF/PE Dumper Version 14.29.30136.0 Copyright (C) Microsoft Corporation. All rights reserved. Dump of file main.obj File Type: COFF OBJECT RELOCATIONS #4 Symbol Symbol Offset Type Applied To Index Name -------- ---------------- ----------------- -------- ------ 0000000B REL32 00000000 C ?create@@YA?AUengine_t@@XZ (struct engine_t __cdecl create(void)) 00000036 DIR32 00000000 9 $SG2851 0000003F REL32 00000000 D ?load@@YAXAAUengine_t@@PBD@Z (void __cdecl load(struct engine_t \u0026amp;,char const *))  We have 3:\n   Symbol      ?create@@YA?AUengine_t@@XZ (struct engine_t __cdecl create(void)) [[nodiscard]] engine_t create() noexcept   $SG2851 dunno   ?load@@YAXAAUengine_t@@PBD@Z (void __cdecl load(struct engine_t \u0026amp;,char const *)) void load(engine_t\u0026amp; engine, cstring level) noexcept    If we now look at what symbols we can find in engine.lib:\nPS D:\\cpplecture\\linker\\game\u0026gt; DUMPBIN.EXE /SYMBOLS engine.lib Microsoft (R) COFF/PE Dumper Version 14.29.30136.0 Copyright (C) Microsoft Corporation. All rights reserved. Dump of file engine.lib File Type: LIBRARY COFF SYMBOL TABLE 000 010575B8 ABS notype Static | @comp.id 001 80010191 ABS notype Static | @feat.00 002 00000002 ABS notype Static | @vol.md 003 00000000 SECT1 notype Static | .drectve Section length 2F, #relocs 0, #linenums 0, checksum 0 005 00000000 SECT2 notype Static | .debug$S Section length 78, #relocs 0, #linenums 0, checksum 0 007 00000000 SECT3 notype Static | .text$mn Section length A9, #relocs 1, #linenums 0, checksum 47C05A6 009 00000000 UNDEF notype () External | ??_U@YAPAXI@Z (void * __cdecl operator new[](unsigned int)) 00A 00000000 SECT3 notype () External | ?update@engine_t@@QAEXN@Z (public: void __thiscall engine_t::update(double)) 00B 00000010 SECT3 notype () External | ?spawn@engine_t@@QAE?AUentity_t@@XZ (public: struct entity_t __thiscall engine_t::spawn(void)) 00C 00000060 SECT3 notype () External | ?create@@YA?AUengine_t@@XZ (struct engine_t __cdecl create(void)) 00D 00000000 SECT4 notype Static | .chks64 Section length 20, #relocs 0, #linenums 0, checksum 0 String Table Size = 0x6B bytes COFF SYMBOL TABLE 000 010575B8 ABS notype Static | @comp.id 001 80010191 ABS notype Static | @feat.00 002 00000002 ABS notype Static | @vol.md 003 00000000 SECT1 notype Static | .drectve Section length 2F, #relocs 0, #linenums 0, checksum 0 005 00000000 SECT2 notype Static | .debug$S Section length 74, #relocs 0, #linenums 0, checksum 0 007 00000000 SECT3 notype Static | .text$mn Section length 67, #relocs 0, #linenums 0, checksum 789BEE7A 009 00000000 SECT3 notype () External | ?parse@@YA?AUjson@@PBD@Z (struct json __cdecl parse(char const *)) 00A 00000010 SECT3 notype () External | ?get_object@@YA?AUjson_object@@ABUjson@@PBD@Z (struct json_object __cdecl get_object(struct json const \u0026amp;,char const *)) 00B 00000020 SECT3 notype () External | ?get_array@@YA?AUjson_array@@ABUjson@@PBD@Z (struct json_array __cdecl get_array(struct json const \u0026amp;,char const *)) 00C 00000040 SECT3 notype () External | ?get_string@@YA?AUstring_view@@ABUjson@@PBD@Z (struct string_view __cdecl get_string(struct json const \u0026amp;,char const *)) 00D 00000060 SECT3 notype () External | ?get_number@@YANABUjson@@PBD@Z (double __cdecl get_number(struct json const \u0026amp;,char const *)) 00E 00000000 UNDEF notype External | __fltused 00F 00000000 SECT4 notype Static | .rdata Section length 8, #relocs 0, #linenums 0, checksum 0, selection 2 (pick any) 011 00000000 SECT4 notype External | __real@0000000000000000 012 00000000 SECT5 notype Static | .chks64 Section length 28, #relocs 0, #linenums 0, checksum 0 String Table Size = 0xE6 bytes  We get the list of all symbols in both object files: engine.obj and json.obj\nReferences:  https://docs.microsoft.com/en-us/cpp/build/reference/overview-of-lib?view=msvc-170 https://llvm.org/docs/CommandGuide/llvm-ar.html https://mottosso.gitbooks.io/clang/content/building_a_static_library.html https://gist.github.com/jsanchezuy/23b1fc8c592455f1bb84 https://man7.org/linux/man-pages/man1/objdump.1.html https://www.computerhope.com/unix/uld.htm https://docs.microsoft.com/en-us/cpp/build/reference/compiler-options?view=msvc-170 https://docs.microsoft.com/en-us/cpp/build/building-on-the-command-line?view=msvc-170 https://linux.die.net/man/1/ar https://en.cppreference.com/w/cpp/language/translation_phases https://en.wikipedia.org/wiki/COFF https://en.wikipedia.org/wiki/Executable_and_Linkable_Format https://docs.microsoft.com/en-us/cpp/build/reference/dumpbin-options?view=msvc-170 https://www.youtube.com/watch?v=a5L66zguFe4 (CppCon 2017: Michael Spencer “My Little Object File: How Linkers Implement C++”) https://www.geeksforgeeks.org/extern-c-in-c/ https://www.ibm.com/docs/en/i/7.2?topic=linkage-name-mangling-c-only http://web.mit.edu/tibbetts/Public/inside-c/www/mangling.html  ","date":1638399600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638399600,"objectID":"f69e2384dc3f3c3b982cbf8586cae83f","permalink":"/posts/cpp_compilation_process/","publishdate":"2021-12-02T00:00:00+01:00","relpermalink":"/posts/cpp_compilation_process/","section":"posts","summary":"In this workshop / how to you learn how the C++ Compilation process works in a nutshell. Before you can start you need to do some form of preps as described in the next step... (This is a workshop created for Breda University of Applied Sciences Games BA Technology Course 2021)","tags":["lecture","gamedev","github","cpp","workshop"],"title":"C++ Compilation process","type":"posts"},{"authors":["Simon Renger"],"categories":["portfolio"],"content":"The Machinery is a lightweight hackable modern game engine, written in plain C.Written in plain C. Boots instantly. Responsive UI. Recompiles in seconds. Supports hot reloading everywhere. Made to be hacked. Extend or modify with plugins. The flexibility of a custom engine with the convenience of a ready-made one.Maximum performance. Fiber-based job system. Modern rendering architecture.\nMy main responsibilities Tools Engineering\nDuring my internship I have been in charge for multiple improvements of the UX of the Editor. I have introduced different views to the Asset Browser, which are modeled after the Windows Explorer: Grid, List, Detail View. Besides, I have introduced the concept of asset labels, which allows for quick grouping assets together with labels. Also the user can filter with those labels assets.\nThe bigger tasks was to introduce a Debugger to our Visual Scripting language. This was were most of my time went. I introduced breakpoints, flow visualization, step through and a watch value functionality.\nQA Engineering\nI am working with GitHub Actions. It verifies that our engine can be built on Windows (msvc and clang-cl) and Linux (our test environment is Ubuntu) with the clang tool chain. Besides I have been adding functionality of integration tests to the CI system on the server, Integration tests and unit tests are running side by side in specific intervals (Unit tests every commit or PR)\n","date":1622553000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622553000,"objectID":"25484e18f2252d0aa5ac7f457e3e5ebb","permalink":"/project/themachinery/","publishdate":"2021-06-01T14:10:00+01:00","relpermalink":"/project/themachinery/","section":"project","summary":"At [OurMachinery](http://www.ourmachinery.com) I have been working on The Machinery a new lightweight modular Game Engine. My role was Tools Engineer and QA Engineer  [more information](/project/themachinery/)","tags":["windows","c","cpp","linux","github","qa"],"title":"Internship at OurMachinery","type":"project"},{"authors":["Simon Renger"],"categories":["services"],"content":"Tools Development My specializations are:\n UI / UX improvements commandline tools LLVM\u0026rsquo;s libclang tooling  QA Engineering / Management My specializations are:\n setting up your QA Pipeline on GitHub / GitLab, Jenkins Server setting up tests: integration tests, unit tests integration of analytic tools improving existing pipelines with new tools  Teaching / Coaching  Programming in C++ Programming in C UI / UX fundamentals for Tools programming  Availability I\u0026rsquo;m available for tools development and QA Engineering / Management, coaching and community coordination. Please contact me if you are interested in my services.\n","date":1588342200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588342200,"objectID":"4133a7a74a7f7a0676f1a74d9e43d8b9","permalink":"/page/services/","publishdate":"2020-05-01T15:10:00+01:00","relpermalink":"/page/services/","section":"page","summary":"Tools Development My specializations are:\n UI / UX improvements commandline tools LLVM\u0026rsquo;s libclang tooling  QA Engineering / Management My specializations are:\n setting up your QA Pipeline on GitHub / GitLab, Jenkins Server setting up tests: integration tests, unit tests integration of analytic tools improving existing pipelines with new tools  Teaching / Coaching  Programming in C++ Programming in C UI / UX fundamentals for Tools programming  Availability I\u0026rsquo;m available for tools development and QA Engineering / Management, coaching and community coordination.","tags":[],"title":"Services","type":"page"},{"authors":["Simon Renger"],"categories":["portfolio"],"content":"Kari is a single player, adventure game in which you are stuck on the island of the Nordic gods. It is your job to complete quests given by the gods and the islands inhabitants in order to rebuild your boat.\n   Game teaser, basic game overview\n My main responsibilities I am mainly responsible for the QA pipeline and the Jenkins set up. I created a Jenkins Utility library. This Jenkins groovy script collection helps us create the QA pipeline we want on the school\u0026rsquo;s Jenkins server. The library contains a collection of functions to communicate with Helix Swarm, Mantis and Discord. It supports the automated testing pipeline in Unreal Engine. Furthermore, it can pack and build UE4 projects.\nBesides, I have created a prototype of a Commit Testing Tool in WPF (Windows Presentation Foundation) and Material Design for WPF.\nP4CommitTester - prototype The purpose of this tool is it to test local or online Perforce changelists before they can be submitted or turned into a Swarm review. The tool has a simple toml configuration file in which the automated tests can be specified (e.g. unit tests, map tests/ funcionality tests).\nOne can also define pre/post steps. They will be executed before the actual tests run e.g. shelve all other changelists. This set up makes it possible for the tool to work with any kind of engine or software. When tests are finished, the tool will check the return code of the application and react appropriately (most test applications return EXIT_FAILURE on failure).\nCurrently, the tool can only communicate with the Jenkins API to run online tests / builds.\nImages    Changelist Overview        List of all possible changelists. The default changelist is excluded because it is not really a changelist.       Selected Changelist Details        You can shelve (if it is a shelved changelist), unshelve and test the current changelist.       Test configuration        Toml file to configure the tool to run tests.       Test Results        In case the tests were ok the user can create a review or commit directly. If they were not successful the user would find the log here.    Project Overview    Project Information      Type: Single player, adventure game   Duration: September 2019 - Ongoing Development   Teamsize: 6 programmers, 10 designers, 12 artists, 1 producer   Roles: QA \u0026amp; Tools engineer   Engine: Unreal Engine   Platform: Windows   Languages: C++, Jenkins Groovy, C#   Technologies: Jenkins, Visual Studio, C# UWP, C# WPF    ","date":1586992200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586992200,"objectID":"ab50f95474071f3d93c9d857942a3aa7","permalink":"/project/kari/","publishdate":"2020-04-16T00:10:00+01:00","relpermalink":"/project/kari/","section":"project","summary":"Kari is a single player, adventure game in which you are stuck on the island of the Nordic gods. [more information](/project/kari/)","tags":["windows","ue4"],"title":"Kari (Published)","type":"project"},{"authors":["Simon Renger"],"categories":null,"content":"","date":1573847400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573847400,"objectID":"e90315fa070f77cde9c32f8632395690","permalink":"/talk/imposter-effect-lightning-talk-meetingcpp19/","publishdate":"2019-12-13T23:03:14+01:00","relpermalink":"/talk/imposter-effect-lightning-talk-meetingcpp19/","section":"talk","summary":"A lightning talk about the imposter effect.","tags":["cpp","meetingcpp","cpp","talk"],"title":"Imposter Effect Lightning Talk Meetingcpp 2019","type":"talk"},{"authors":["Simon Renger"],"categories":["portfolio"],"content":"In this open world flight game my responsibilities vary from what is needed for the current state of development. Mainly I am focused with tools design and tools programming but also gameplay programming such as the camera. This project allows me to dive into Unity’s new Data-Oriented Technology Stack (DOTS) due to its massive performance promises especially in terms of level streaming.\nMy main responsibilities Making sure that we utilize DOTS to its fullest extent, research into how DOTS can improve our gameplay and allow for benefits. Besides, I am responsible for implementing a quest system with the help of DOTS.\n   Project Information      Type: Open World flight simulation game with focus on exploration an living world.   Duration: September 2019 - January 2020   Teamsize: 9 Programmers, 12 Designers, 8 Artists and 1 Producer   Roles: Tools programmer   Engine: Unity   Platform: Windows   Languages: C#   Technologies: Unity DOTS, Visual Studio, Jenkins, Perforce       Project Highlights     We are utilizing the new data oriented systems (DOTS) to allow a better open-world experience.    ","date":1569766200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569766200,"objectID":"ee1ab1170c7dcc1c012518077237f55d","permalink":"/project/seaplane/","publishdate":"2019-09-29T15:10:00+01:00","relpermalink":"/project/seaplane/","section":"project","summary":"Skye is an open world exploration flight game. Utilizing the new Data-Oriented Technology Stack (DOTS). Set in the Scottish Hebrides. [more information](/project/seaplane/)","tags":["windows","unity"],"title":"Skye (Published)","type":"project"},{"authors":["Simon Renger"],"categories":["portfolio"],"content":"The tomorrow engine is a cross platform C++ game framework which allows the creation of deterministic linear card games. The player had to fight the opponent and the 3 monsters in the game. The game we created with this was called Raptoads. The Framework supported Playstation 4 and Windows 10.\nGameplay trailer   My main responsibilities Apart from being the Tech lead / Team lead of the 11 programmers, I have been in charge for the core architecture. Besides, I have been responsible for implementing and designing the extensive tooling and pipeline for content creation and content management. The tooling was created in web technologies (electron \u0026amp; SQL Database), which allowed us for quick and rapid iterations.\nCore Architecture The application was split into four different modules. The Framework (TBSG) served the Client as well as the Server with basic utilities. Besides, we had the Network layer.\nWhen designing the modules, I followed the architecture guideline for our game: determinstic linear card games. That resulted in a \u0026ldquo;data oriented\u0026rdquo; approach.\nTooling - The Hub The framework came with its own tooling which was written in JavaScript and Electron. It served as the main content creation tool for Designers. The tool offered the following functions:\n AI Optimization for the QA Test games Modifiying the underlying content database (SQL) source contol of our Lua card scripts UI Editor Lua Script validation     Project Information      Duration: 16 Weeks - February to July 2019   Team size: 11 Programmers, 5 Designers, 8 Artists and 1 Producer   Roles: Tech Lead, Tools programmer, Scrum Master   Engine: Custom cross-platform C++ Engine with Electron Tooling (Tomorrow Engine)   Platform: Windows, Playstation 4   Languages: C++, JavaScript, Lua, SQL   Technologies: Lua Scripting, Online Crossplay Multiplayer, Event/HTTP/UI handling with PS4 Support.       Project Highlights     Scripting Pipeline: A Lua dialect which allowed designers to quickly develop with our tooling the card behaviour.   Scripting source control integration - via the tooling   Google Drive integration \u0026amp; Sheets   Utility AI - custimizeble via the tooling   Custom Tooling written with Web technologies for quick iterations, tool of choice: Electron \u0026amp; MariaDB   Playstation 4 Support: The engine supported Playstation 4    ","date":1556738340,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556738340,"objectID":"f2ee67ea04abfeaabd8b073b78e2a667","permalink":"/project/tbsg/","publishdate":"2019-05-01T20:19:00+01:00","relpermalink":"/project/tbsg/","section":"project","summary":"A multiplayer crossplatfrom c++ determinstic linear card game engine developed in 16 weeks. Targeted for Playstation 4 and Windows 10 [more information](/project/tbsg/)","tags":["cpp","ps4","windows"],"title":"“Tomorrow Engine“","type":"project"},{"authors":["Simon Renger"],"categories":["portfolio"],"content":"I have been giving workshops and lectures since my second year at the university. This is a great way of learning new skills and sharing the gained knowlegde with others. It also allows for a great flow of feedback. This is why I initiated the C++ learning comminity at our school (called C++ Guild)\nIn the last two years I have been giving various lectures and workshops on the following topics:\n   Lecture / Workshop Description     How do programmers think? A lecture which uses minecraft to illustrate how abstract thinking works as well as how we can improve communication internally.   C++ type deduction In three workshops I have covered the basics of the C++ type deduction: template type deduction, auto type deduction, decltype deduction, decltype auto deduction, lambda type deduction.   C++ Compiler and linker steps This presentation explained the compiler steps in C++ and the linker steps.   Allocators are handles to the heap This workshop introduced the concept of polymorphic memory allocations in C++17 and how to use them as well as how to implement them in C++14. Besides, there was a brief introduction on Memory Management.   C++ special member function rules In this talk I covered the special member function rules in C++.   C# for designers and artists This is a workshop series of 16 weeks in which me and 2 other students taught C# to fellow Design and Art students. We ran this course in year 2 and also in year 3. We iterated on the idea and changed the concept to a Quest-based learning environment. This allows students to progress at their own pace because they have an overview on how they progress.   C++ Memory Managment: Introduction In two parts I introduced Memory Managment in C++ and the underlying concepts.   C++ Memory Managment: Write your own STL compatible allocator This workshop explained how to implement in C++ 14 an STL compatible polymorphic like allocator and memory resource environment. This workshop was targeted for Windows and Playstation 4 and was held in 4 parts.    ","date":1544905140,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1544905140,"objectID":"090614a95d122e3de2e4615ff89dc3ec","permalink":"/project/tutoring/","publishdate":"2018-12-15T21:19:00+01:00","relpermalink":"/project/tutoring/","section":"project","summary":"Besides being a student I am giving lectures and workshops at university about serveral programming related topics: Memory Management, C# for Design an art and organizing the C++ learning community. How to programmer think? [more information](/project/tutoring/)","tags":["cpp","teaching","windows"],"title":"Tutoring","type":"project"}]