[{"authors":["admin"],"categories":null,"content":"I am Simon, a Game Programming master student as well as a contractor.\nI am striving for new opportunities to learn and innovate. I love my work as much as I love sharing knowledge with others. I do not shy away from a challenge that involves picking up different roles that move a project forward. I am mainly interested in tools design as well as QA Engineering.\nI am always looking for new opportunities to work on as contractor. Just shoot me an e-mail.\n","date":1622553000,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1622553000,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am Simon, a Game Programming master student as well as a contractor.\nI am striving for new opportunities to learn and innovate. I love my work as much as I love sharing knowledge with others. I do not shy away from a challenge that involves picking up different roles that move a project forward. I am mainly interested in tools design as well as QA Engineering.\nI am always looking for new opportunities to work on as contractor.","tags":null,"title":"Simon Renger","type":"authors"},{"authors":null,"categories":["research","gamedev"],"content":"While I was working on my Masters in Game Technology at Breda University of Applied Sciences (BUas), I came across an interesting problem: How am I executing a systematic review of GitHub repositories?\nWhen searching on the Internet, it was challenging to find good sources. I came across the fantastic work from the Department of Information and Computing Sciences, Utrecht University: A Systematic Review of Open Source Clinical Software on GitHub for Improving Software Reuse in Smart Healthcare by Zhengru Shen and Marco Spruit. They created a paper that explains step-by-step how to do a systematic review of GitHub repositories! As I mentioned in my previous blog post: \u0026ldquo;None of the standard literature regarding methodology covers this case. Okay, okay… GitHub is relatively new and special!\u0026quot;.\nYou can basically follow along and do as they described. See my previous blog post for a TL;DR version. I describe how to execute the method of collecting data a little bit more practical with a python script-based example. The example code you can find, of course, on GitHub itself: collect-data-from-github\nThis is all great but I wanted to discuss the data collection and processing part a bit more. As I found out, it is very different for each topic what kind of data you need to collect from the GitHub REST API. Also, it is important to discuss the reasoning behind the data and its processing\nTL;DR When gathering data from GitHub, we need to know in advance what we need for our study. There are 2 data sets we can collect: Textual data and numerical data. The textual data can be separated into Source Code and metadata. The metadata contains tags, topics, descriptions, README, and documentation links. The Numeric values are either date, such as the last date the project was updated, or values, such as the size of the project, the number of people staring the project issues, etc. The textual and numeric data must always be analyzed within the proper context. There are several existing tools that can help one to conduct the analyses.\nA few important takeaways about some specific data categories:\n A.I. is important to make sense out of Textual context such as README files or documentation in case manual labor shall be avoided. Such as IBM Watson Natural Language Understanding Natural Language Toolkit (NLTK) for python [9] or Google\u0026rsquo;s Natural Language A.I. [10]. Source Code analyzes can be done by tools such as static analyzes tools, documentation tools or code base visualizers. Such as Sourcetrail , Source Graph. Stars are a indication of interest in a project which needs to be set into a proper context, which can be done with tools such as RepoReaper and GHTorrent. The second meaning of stars is just to bookmark something which does not guarantee that I am actually interested in this project. Also, the risk of distortion from fake stars or promotion actions can have an influence on star growth. Commits are a not reliable source to use to calculate if a project is successful or popular when matched with stars. Due to the reason that every project has their own commit policy [14]. Forks are somewhat more reliable since there is a strong indication that they are connected with the number of stars. However, one should keep in mind that there is also the ability to have bots that do nothing else than fork projects. [14]  What kind of data can you collect on GitHub? GitHub provides a REST API [2], which is an service that allows the user to send request to it in a defined way (protocol) via the HTTP protocol and receive answers [3]. The service provides a lot of entry points, for a systematic review of GitHub Projects the search endpoint, the REST API part that is concert with searching for repositions, is very important. Besides this, there are a few other endpoints that will be very useful which are listen in Table 1.\n   Endpoint Description     Repositories \u0026ldquo;The Repos API allows access information about GitHub repositories.\u0026rdquo;   Projects \u0026ldquo;The Projects API let you fetch projects in a repository.\u0026rdquo;   Organizations \u0026ldquo;The Organizations API let you fetch information about a GitHub organizations.\u0026rdquo;    Table 1: Useful other API endpoints than the Search.\nFrom the GitHub REST API you can gather two kind of main data types: Numerical and Textual. These can be used for further analyzes. There are two different textual information you can collect on GitHub: Source Code and Meta data to describe the repository [1,2].\nThe Source Code for example can be scanned manually or via a static analyzes tool or any other tool that can understand source code and gives us a meaning full understanding of it. Alberto S.Nuñez-Varela et al., has shown in their study Source code metrics: A systematic mapping study [5] what kind of metrics can be applied when analyzing source code. The results of their work are very interesting since they report of almost 300 source code metrics. They also concluded that object oriented metrics have been mostly found and more research is needed to conduct to gather metrics for more feature oriented aspects.\nFurthermore, to analyze source code from a practical point of view. If one is looking for certain patterns, tools to visualize a codebase are useful. Sourcetrail is such an open source tool that lets you navigate through the code base virtually. An other useful tool is Source Graph which allows you to search your code and 2M+ open source repositories [6].\nThe other meta data such as README files, wiki or documentation stored in the project needs to be analyzed by hand or with the raise of AI one can make use of tools such as IBM Watson Natural Language Understanding [7] to help understand and process natural language. How you can use IBM\u0026rsquo;s Watson is greatly explained in the following article: Getting started with NLP using IBM Watson Studio by Aritro Mukherjee [8]. There are, of course, other alternatives such as Natural Language Toolkit (NLTK) for python [9] or Google\u0026rsquo;s Natural Language AI [10]. These AI driven tools can help to identify themes, topics or search for the needed information within the meta data of a repository.\nIn the space of numerical values we have also again two types: Dates and numerical values [1,4]. The dates can be used for our limitations since GitHub gives us only 3 dates [4]: pushed_at, updated_at,created_at. The meaning behind them can be described as updated_at will be updated any time the repository object is updated. A repository object is updated when one, for example, update the description or the primary language of the repository. On the other hand, pushed_at represents the date and time of the last commit. Since updated_at represents the timestamp of the last change to the repository which might be a be a commit, but it may also be other things, such as changing the description of the repo, creating wiki pages, etc. That is why one can say that commits are a subset of updates, and the pushed_at timestamp will therefore, either be the same as the updated_at timestamp, or it will be an earlier timestamp [2,11].\nThe other numeric values of interest can be gather from a GitHub Repository are described in Table 2:\n   Numeric Value Description     Stargazers \u0026ldquo;Stargazers refers to the number of times a repository is bookmarked. It reflects an approximate level of interest in the repository\u0026rdquo; [1,2]   Forks \u0026ldquo;A fork is a copy of a repository. Forking is necessary for developers to contribute a project. Forks refers to the number of forks.\u0026rdquo; [1,2]   Contributors \u0026ldquo;The number of contributors who have worked for a repository.\u0026rdquo; [1,2]   Commits \u0026ldquo;The total number of commits.\u0026rdquo; [1,2]   Issues \u0026ldquo;Issues is the number of open issues in a repository\u0026rdquo; [1,2]   Size of source codes \u0026ldquo;The size is valued as the size of the whole repository (including all of its history), in KB.\u0026rdquo; [1,2]   Size of README file \u0026ldquo;The size of the README file of a repository, in B\u0026rdquo; [1,2]    Table 2: Overview of numerical values one can gather on GitHub*\nThis data can be used and processed with methods such as GAM which are a extension of generalized linear models (GLMs), a GAM is an additive modeling technique that captures the impact of the predictive variables through smooth functions [1,2].\nThe meaning of numeric values: Stars,Forks and Commits Zhengru Shen and Marco Spruit as well as of other researchers [13,14,15] are suggesting to use stargazers (stars) as indication of popularity. Research has shown that the \u0026ldquo;stargazers-based classifier [\u0026hellip;] to exhibit high precision (97%)\u0026rdquo; when trying to find retrieving engineered software projects [16]. Munaiah, N at all Research results in \u0026ldquo;RepoReaper\u0026rdquo;. RepoReaper \u0026ldquo;is a tool used to assess a GitHub repository in the form of a score. It considers a number of different attributes in order to perform a thorough assessment.\u0026rdquo; [17] This tool is intend to be used with \u0026ldquo;together with a database of metadata provided by the GHTorrent project, reaper considers both contextual information such as commit history as well as the contents of the repository itself [17].\u0026rdquo; RepoReaper can be helpful in order to score the results of your systematic review of a subset of specific projects.\nThe Meaning of stars from a developer point of view However it is important to discuss the meaning of stars, forks, and commits. As stated by GitHub, stars are a method to keep track of projects that you find interesting or discover via the explore/ \u0026ldquo;news\u0026rdquo; feed related projects [18]. They are also frequently used by the community as bookmarks [15]. As explained in several sources, such as from Zhengru Shen and Marco Spruit and a lot of other researchers [13,14,15] ,stars have two major functions. They function as an indication that someone likes the project or that they want to book mark the project [15]. A developer on OpenSource Stackexchange states this perfectly: \u0026ldquo;[…] Users on the GitHub website are able to \u0026ldquo;star\u0026rdquo; other people\u0026rsquo;s repositories, thereby saving them in their list of Starred Repos. Some people use \u0026ldquo;stars\u0026rdquo; to indicate that they like a project, other people use them as bookmarks so they can follow what\u0026rsquo;s going on with the repo later. […]\u0026rdquo; 15, Left SE On 10_6_19].\nHudson Borges et al, provide the academic data to the statements gathered on OpenSource Stackexchange [15] in their survey of 791 developers describe how they use stars on GitHub[14]. Their Table 2 [14] shows this.\nNote: Note that one answer can receive more than one theme therefore numbers might not add up to 791 for more details see Paper.\n   Reason Total %     To show appreciation 415 52.5   Bookmarking 404 51.1   Due to usage 290 36.7   Due to recommendations 36 4.6   Unknown reasons 5 0.6    Table 3. Why do users star GitHub repositories? (95% confidence level with a 3.15% confidence interval). based on Table 2 from \u0026ldquo;What’s in a GitHub Star? Understanding Repository Starring Practices in a Social Coding Platform\u0026rdquo; by Hudson Borges at al.\nThe reason why one needs to look at stars critical is that from technical perspective they are simple to fake. Since it is very simple to just create GitHub fake accounts and write a bot that just likes your project [15]. Besides the simplicity of faking stars a huge growth of stars might be the result of a promotion on social media (e.g. twitter) [13]. Hudson Borges at al suggests that \u0026ldquo;when ranking projects, we should check whether stars are result of active promotion\u0026rdquo; in their recommendations for researchers at the end of their journal article [15]. There are two main reasons why we should look critically on stars. Firstly one is that they might be created through fake accounts. Secondly they might be a result of active promotion on social media platforms.\nMoreover Hudson Borges et al, suggested in their final conclusion that stars are important for users to pick a project. The study found out that 3 out of 4 developers (of the 791 developers surveyed developers) check the stars metric before using or contributing to projects. Despite this strong indication between stars and popularity, the paper suggested that other factors such as code quality and documentation are important. Both factors can be evaluated with RepoReaper in order to create a relationship between popularity and documentation / code quality [16,17]. For a lot of developers stars are a great indication to either contribute to a project but not just other factors such as code quality and documentation necessary.\nForks and commits Research has shown that forks can be used to evaluate the popularity of a project since there is a strong correlation between stars and forks [15]. It is noteworthy to say that there are fork bots out there that just fork a project automatically since this can also be done automatic via the REST API [2]. That bots may create forks of projects might be important to consider when using the fork value as a indication for popularity. Forking a project via bots is not that frequently done as for stars that this can be ignored but still it is important to keep this in mind when building an argumentation about the correlation between stars and forks.\nCommits however only show a weak correlation with stars [15]. This can be explained with the practical reason that the way a project handles its commits can differ greatly, since every bigger project has their own policies in regards to how often one shall commit and how big they shall be. For example, The QT project has its own policies Commit Policy or the KDE Projects Policies/Commit Policy. Looking at this from a developer point of view, it explains than that the number of commits in relation to stars or in general towards the project popularity cannot be a hard link. The main indication of commits is to show how actively maintained a project is. Every commit will change the pushed_at date. The fact that every project might have their own commit policy explains why the number of commits and the projects popularity has just a weak link.\nTakeaways The main takeaways are that when one is analyzing GitHub repositories, one has to take the different limiting factors into account. These limiting factors are sometimes better described by users of GitHub than by pure academia. The best example is the discussion on Opensource Stack Exchange \u0026ldquo;GitHub Stars\u0026rdquo; is a very useful metric. But for what? from Left SE On 10_6_19. Moreover, it is important to realize what is the meaning behind the possible metrics. There has been some great work done by several authors [1,5,13,16]. Therefore it can be said that:\n A.I. is important to make sense out of Textual context such as README files or documentation in case manual labor shall be avoided. Such as IBM Watson Natural Language Understanding Natural Language Toolkit (NLTK) for python [9] or Google\u0026rsquo;s Natural Language A.I. [10]. Source Code analyzes can be done by tools such as static analyzes tools, documentation tools or code base visualizers. Such as Sourcetrail , Source Graph. Stars are a indication of interest in a project which needs to be set into a proper context, which can be done with tools such as RepoReaper and GHTorrent. The second meaning of stars is just to bookmark something which does not guarantee that I am actually interested in this project. Also, the risk of distortion from fake stars or promotion actions can have an influence on star growth. Commits are a not reliable source to use to calculate if a project is successful or popular when matched with stars. Due to the reason that every project has their own commit policy [14]. Forks are somewhat more reliable since there is a strong indication that they are connected with the number of stars. However, one should keep in mind that there is also the ability to have bots that do nothing else than fork projects. [14]  References [1] Department of Information and Computing Sciences, Utrecht University: A Systematic Review of Open Source Clinical Software on GitHub for Improving Software Reuse in Smart Healthcare by Zhengru Shen and Marco Spruit\n[2] GitHub REST API (accessed on 02 April 2022).\n[3] What is a REST API? (accessed on 02 April 2022).\n[4] GitHub Repositories (accessed on 02 April 2022).\n[5] Alberto S. Nuñez-Varela, Héctor G. Pérez-Gonzalez, Francisco E. Martínez-Perez, Carlos Soubervielle-Montalvo, Source code metrics: A systematic mapping study, Journal of Systems and Software, Volume 128, 2017 https://doi.org/10.1016/j.jss.2017.03.044.\n[6] Source Graph (accessed on 02 April 2022).\n[7] BM Watson Natural Language Understanding. Available online: https://www.ibm.com/cloud/watson-natural-language-understanding (accessed on 02 April 2022).\n[8] Getting started with NLP using IBM Watson Studio by Aritro Mukherjee (accessed on 02 April 2022)\n[9] Natural Language Toolkit (NLTK) (access on 02 April 2022)\n[10] Google\u0026rsquo;s Natural Language AI (access on 02 April 2022)\n[11] Difference between “updated_at” and “pushed_at” in repositories list response (access on 02 April 2022)\n[12] Wood, S.N. Generalized Additive Models: An Introduction with R; Chapman and Hall/CRC: London, UK, 2006.\n[13] Characterizing and predicting the popularity of github projects by Hudson Silva Borges https://repositorio.ufmg.br/handle/1843/BIRC-BBLN2S (access on 02 April 2022)\n[14] Hudson Borges, Marco Tulio Valente, What’s in a GitHub Star? Understanding Repository Starring Practices in a Social Coding Platform, Journal of Systems and Software,Volume 146, 2018, Pages 112-129, ISSN 0164-1212, https://doi.org/10.1016/j.jss.2018.09.016.\n[15] \u0026ldquo;GitHub Stars\u0026rdquo; is a very useful metric. But for what? asked by Left SE On 10_6_19 on opensource.stackexchange.com (access on 02 April 2022)\n[16] Munaiah, N., Kroh, S., Cabrey, C. et al. Empir Software Eng (2017) 22: 3219. https://doi.org/10.1007/s10664-017-9512-6\n[17] RepoReaper (access on 02 April 2022)\n[18] Saving repositories with stars (access on 02 April 2022)\n","date":1649113200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649113200,"objectID":"7133cf95a5c10ca23873501c026c3230","permalink":"/posts/systematic_review_on_github_method_discussion/","publishdate":"2022-04-05T00:00:00+01:00","relpermalink":"/posts/systematic_review_on_github_method_discussion/","section":"posts","summary":"When conducting a systematic review on GitHub its important to realize that you need to know the data. When gathering data from GitHub, we need to know in advance what we need for our study. There are 2 data sets we can collect: Textual data and numerical data. Also there are great tools out there that can help us...","tags":["research","github"],"title":"GitHub Systematic Review: Know your data.","type":"posts"},{"authors":null,"categories":["research","gamedev"],"content":"While I was working on my Masters in Game Technology at Breda University of Applied Sciences (BUas), I came across an interesting problem: How am I executing a systematic review of GitHub repositories?\nNone of the standard literature regarding methodology covers this case. Okay okay\u0026hellip; GitHub is relatively new and special!\nThe lack of answers in literature led me into the wild of the Internet. Sadly when googling \u0026lsquo;Systematic Review of GitHub Repositories\u0026rsquo;, you do not find a \u0026ldquo;HowTo\u0026rdquo; or actually a good GitHub repository with some software.\nThat I find little on regular Google is interesting because Google Scholar gives you a lot of entries when looking for Reviews on GitHub. Sadly, many of these reviews are, as per usual, behind a paywall. Moreover, those papers usually just claim, \u0026ldquo;We did this \u0026hellip; description,\u0026rdquo; but there is seldom any code to be found, or if there is code, it is written in some obscure language an average Game Developer does not use\u0026hellip;\nWell, I just adjusted my search a bit. Finally, I came across this fantastic article from the Department of Information and Computing Sciences, Utrecht University: A Systematic Review of Open Source Clinical Software on GitHub for Improving Software Reuse in Smart Healthcare by Zhengru Shen and Marco Spruit. They did a fantastic job by creating a paper that explains step-by-step how to do a systematic review of GitHub repositories!\nLet me give you a TL;DR (for more details, you need to read my paper later or the original paper link above):\nData Extraction\n  We do a preliminary search of our topic with some keywords or topics of our liking by using GitHub Search and GitHub Topics.\n  We try this in multiple languages to find the correct language (I am talking about natural languages such as English). Maybe our specific topic is more common in Spanish than English, or we need to analyze both. This is important to know.\n  Might we already have a time frame based on our literature review? This is important to take into account when searching for anything on GitHub.\n  We also need to decide: Are the Programming Languages important or not? In general, what is needed from this search for our data analysis? For this, I recommend opening the REST API\u0026rsquo;s reference manual: GitHub search REST API. This has a list of things you can extract.\n4.1 Do I need some extra information besides the repository? Or the byte size usage is essential? If yes, check the rest of the API\u0026rsquo;s documentation. Check out the API\u0026rsquo;s Reference\n  We connect to the GitHub search REST API with our python script using a token: How to use a token to authentify? We are using Python and PyGitHub, which does most of the work for us.\n  We can define multiple queries for the search, if needed for your topic. GitHub allows you to search besides regular queries such as \u0026ldquo;scripting languages\u0026rdquo; also for topics: \u0026ldquo;topic:scripting-languages\u0026quot;. Using topic queries besides regular queries may increase the results of your search. Moreover, you can exclude things. For example, if you wanted to exclude all Visual Studio Extensions from your search, all you need to do is: \u0026ldquo;scripting languages NOT Visual+Studio\u0026rdquo; (The + is important because otherwise, it will ignore only \u0026ldquo;Visual\u0026rdquo; and not \u0026ldquo;Visual Studio\u0026quot;). For more info about the search syntax check: Understanding the search syntax\n  After the last step, you need to store the findings in some form. For example, you can keep your results in a CSV file or in a database.\n  Data Processing\nThis is where my TL;DR ends since this highly depends on your topic. For example, you can do a Descriptive Analysis, an example of which can be found in the original paper. You can also use Generalized Additive Models to process the data. Moreover, you might need an AI to analyze all the README files, descriptions, etc., to extract the extra data you need. Zhengru Shen and Marco Spruit are using Watson to do some of their topic modelings (see 2.4. Topic Modeling).\nAnyways, as a game dev (or a game dev to be), I love sample code and practical things! This is why I really like the paper I mentioned before since the authors also provided the GitHub repository with the source code of the used code for their study. From an academic point of view, this delights my heart since I could reproduce their paper. The developer in me is happy since I have a script example for my paper! The original source code you can find here: ianshan0915/clinical-opensource-projects (a collection of python scripts).\n Warning: This repository is not made to be reused to be used for your own project. You can (like I did), but you still need to read the source code and find things you do not need. As I said, I love, absolutely love sample code! This is what this code is for.\n What does this repo contain? Before we open the GitHub repo and clone it, let\u0026rsquo;s have a look at how they describe it in their paper:\n\u0026ldquo;The data extraction pipeline was written in Python using a third-party library, PyGitHub. The pipeline took the chosen search terms as input and received repository data in JSON. The JSON responses were first filtered and then converted to database records and pushed to tables in a MySQL database. Repositories with no description or no programming language specified were excluded from further analysis for the reason that clinical software was the focus of our study. The whole process is reproducible by running the Python scripts at Reference [22]. Moreover, replacing the search term with others scales the pipeline to other domains.\u0026rdquo; (22: Source Codes of Open Source Clinical Software. Available online: https://github.com/ianshan0915/clinical- opensource-projects (accessed on 25 November 2018)) A Systematic Review of Open Source Clinical Software on GitHub for Improving Software Reuse in Smart Healthcare\nAfter reading the description of their data extraction pipeline, we open the repo. However, there are no instructions on how to use/install the scripts in the README. But no worries, I have a quick summary of what you need:\n PyGitHub communication with the GitHub REST API pandas Watson Developer Cloud Python SDK for analysing the readme files and descriptions textrazor  The conclusion for me is it is excellent that I have the code, but I would spend too much time bending it to my will. I can better follow their lead and write my own script, which is something I think all game devs know somehow.\nMy take on it\nNow, this is what I did, and I ended up with a small Python script that can be used for my purposes. If you need just data collection from GitHub, you can also use it: GitHub search query python\nThe script allows you to write a simple configuration JSON file:\n{ \u0026quot;token\u0026quot;: \u0026quot;my token\u0026quot;, \u0026quot;readme_dir\u0026quot;: \u0026quot;./\u0026quot;, \u0026quot;output\u0026quot;: \u0026quot;./\u0026quot;, \u0026quot;format\u0026quot;: \u0026quot;CSV\u0026quot;, \u0026quot;criteria\u0026quot;: { \u0026quot;time\u0026quot;: { \u0026quot;min\u0026quot;: 2010, \u0026quot;max\u0026quot;: 2022 } }, \u0026quot;terms\u0026quot;: [ \u0026quot;MY SEARCH QUERY\u0026quot;, \u0026quot;MY SEARCH QUERY\u0026quot;, ], \u0026quot;attrs\u0026quot;: [ \u0026quot;id\u0026quot;, \u0026quot;full_name\u0026quot;, ] }  To communicate with the GitHub API, you need a token you can obtain via your GitHub account. This field is optional, and you can also pass it as an argument to the script if you prefer this! As of writing, you have an hourly request rate of 5000 requests. Besides, the script obeys some cooldown time in between requests to not be locked out by the DDOS security of the API. The output field lets you define where your collected data shall be stored. The file name will be repositories_DATE.[csv,json] since I decided to spill out a CSV or JSON file, you can parse it later if you need to. If you need to download README files, you also provide a readme_dir field. They will be stored in there by repo + date. If it is not present, the script assumes you do not need them. The criteria take the time frame from when to when do you need this, which will be used to collect repositories within the defined time frame. The heart of your config is a list of the terms you are searching for:\n\u0026quot;terms\u0026quot;: [ \u0026quot;topic:visual-scripting-language NOT Visual+Studio\u0026quot;, \u0026quot;topic:visual-programming-language NOT Visual+Studio\u0026quot;, \u0026quot;topic:visual-programming NOT Visual+Studio\u0026quot;, \u0026quot;topic:visual-scripting NOT Visual+Studio\u0026quot;, \u0026quot;topic:visual-programming-editor NOT Visual+Studio\u0026quot;, \u0026quot;topic:dataflow-programming NOT Visual+Studio\u0026quot; ],  This will execute the criteria for those search terms every time!\nLast but not least, we have attrs that allow you to define the fields you care about from the REST API repository. There is more info on what to write in there: GitHub search REST API\nNow you might wonder how to actually run this script:\npython github-search-query.py --help  The previous command will give you some ideas on how to run it. But there is a faster way:\npython github-search-query.py config.json  And if you want to pass a token along:\npython github-search-query.py --token my_token config.json  Well that\u0026rsquo;s pretty much it! Have fun data collecting!\n","date":1640646000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640646000,"objectID":"2fb13d2cabc126a9290dda1227c515a4","permalink":"/posts/systematic_review_on_github/","publishdate":"2021-12-28T00:00:00+01:00","relpermalink":"/posts/systematic_review_on_github/","section":"posts","summary":"While I was working on my Masters in Game Technology at Breda University of Applied Sciences (BUas), I came across an interesting problem: How am I executing a systematic review of GitHub repositories?\nNone of the standard literature regarding methodology covers this case. Okay okay\u0026hellip; GitHub is relatively new and special!\nThe lack of answers in literature led me into the wild of the Internet. Sadly when googling \u0026lsquo;Systematic Review of GitHub Repositories\u0026rsquo;, you do not find a \u0026ldquo;HowTo\u0026rdquo; or actually a good GitHub repository with some software.","tags":["research","github","python"],"title":"Systematic review of repositories on GitHub with python (Game Dev Style)","type":"posts"},{"authors":["Simon Renger"],"categories":["portfolio"],"content":"The Machinery is a lightweight hackable modern game engine, written in plain C.Written in plain C. Boots instantly. Responsive UI. Recompiles in seconds. Supports hot reloading everywhere. Made to be hacked. Extend or modify with plugins. The flexibility of a custom engine with the convenience of a ready-made one.Maximum performance. Fiber-based job system. Modern rendering architecture.\nMy main responsibilities Tools Engineering\nDuring my internship I have been in charge for multiple improvements of the UX of the Editor. I have introduced different views to the Asset Browser, which are modeled after the Windows Explorer: Grid, List, Detail View. Besides, I have introduced the concept of asset labels, which allows for quick grouping assets together with labels. Also the user can filter with those labels assets.\nThe bigger tasks was to introduce a Debugger to our Visual Scripting language. This was were most of my time went. I introduced breakpoints, flow visualization, step through and a watch value functionality.\nQA Engineering\nI am working with GitHub Actions. It verifies that our engine can be built on Windows (msvc and clang-cl) and Linux (our test environment is Ubuntu) with the clang tool chain. Besides I have been adding functionality of integration tests to the CI system on the server, Integration tests and unit tests are running side by side in specific intervals (Unit tests every commit or PR)\n","date":1622553000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622553000,"objectID":"25484e18f2252d0aa5ac7f457e3e5ebb","permalink":"/project/themachinery/","publishdate":"2021-06-01T14:10:00+01:00","relpermalink":"/project/themachinery/","section":"project","summary":"At [OurMachinery](http://www.ourmachinery.com) I have been working on The Machinery a new lightweight modular Game Engine. My role was Tools Engineer and QA Engineer  [more information](/project/themachinery/)","tags":["windows","c","cpp","linux","github","qa"],"title":"Internship at OurMachinery","type":"project"},{"authors":["Simon Renger"],"categories":["services"],"content":"Tools Development My specializations are:\n UI / UX improvements commandline tools LLVM\u0026rsquo;s libclang tooling  QA Engineering / Management My specializations are:\n setting up your QA Pipeline on GitHub / GitLab, Jenkins Server setting up tests: integration tests, unit tests integration of analytic tools improving existing pipelines with new tools  Teaching / Coaching  Programming in C++ Programming in C UI / UX fundamentals for Tools programming  Availability I\u0026rsquo;m available for tools development and QA Engineering / Management, coaching and community coordination. Please contact me if you are interested in my services.\n","date":1588342200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588342200,"objectID":"4133a7a74a7f7a0676f1a74d9e43d8b9","permalink":"/page/services/","publishdate":"2020-05-01T15:10:00+01:00","relpermalink":"/page/services/","section":"page","summary":"Tools Development My specializations are:\n UI / UX improvements commandline tools LLVM\u0026rsquo;s libclang tooling  QA Engineering / Management My specializations are:\n setting up your QA Pipeline on GitHub / GitLab, Jenkins Server setting up tests: integration tests, unit tests integration of analytic tools improving existing pipelines with new tools  Teaching / Coaching  Programming in C++ Programming in C UI / UX fundamentals for Tools programming  Availability I\u0026rsquo;m available for tools development and QA Engineering / Management, coaching and community coordination.","tags":[],"title":"Services","type":"page"},{"authors":["Simon Renger"],"categories":["portfolio"],"content":"Kari is a single player, adventure game in which you are stuck on the island of the Nordic gods. It is your job to complete quests given by the gods and the islands inhabitants in order to rebuild your boat.\n   Game teaser, basic game overview\n My main responsibilities I am mainly responsible for the QA pipeline and the Jenkins set up. I created a Jenkins Utility library. This Jenkins groovy script collection helps us create the QA pipeline we want on the school\u0026rsquo;s Jenkins server. The library contains a collection of functions to communicate with Helix Swarm, Mantis and Discord. It supports the automated testing pipeline in Unreal Engine. Furthermore, it can pack and build UE4 projects.\nBesides, I have created a prototype of a Commit Testing Tool in WPF (Windows Presentation Foundation) and Material Design for WPF.\nP4CommitTester - prototype The purpose of this tool is it to test local or online Perforce changelists before they can be submitted or turned into a Swarm review. The tool has a simple toml configuration file in which the automated tests can be specified (e.g. unit tests, map tests/ funcionality tests).\nOne can also define pre/post steps. They will be executed before the actual tests run e.g. shelve all other changelists. This set up makes it possible for the tool to work with any kind of engine or software. When tests are finished, the tool will check the return code of the application and react appropriately (most test applications return EXIT_FAILURE on failure).\nCurrently, the tool can only communicate with the Jenkins API to run online tests / builds.\nImages    Changelist Overview        List of all possible changelists. The default changelist is excluded because it is not really a changelist.       Selected Changelist Details        You can shelve (if it is a shelved changelist), unshelve and test the current changelist.       Test configuration        Toml file to configure the tool to run tests.       Test Results        In case the tests were ok the user can create a review or commit directly. If they were not successful the user would find the log here.    Project Overview    Project Information      Type: Single player, adventure game   Duration: September 2019 - Ongoing Development   Teamsize: 6 programmers, 10 designers, 12 artists, 1 producer   Roles: QA \u0026amp; Tools engineer   Engine: Unreal Engine   Platform: Windows   Languages: C++, Jenkins Groovy, C#   Technologies: Jenkins, Visual Studio, C# UWP, C# WPF    ","date":1586992200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586992200,"objectID":"ab50f95474071f3d93c9d857942a3aa7","permalink":"/project/kari/","publishdate":"2020-04-16T00:10:00+01:00","relpermalink":"/project/kari/","section":"project","summary":"Kari is a single player, adventure game in which you are stuck on the island of the Nordic gods. [more information](/project/kari/)","tags":["windows","ue4"],"title":"Kari (Published)","type":"project"},{"authors":["Simon Renger"],"categories":null,"content":"","date":1573847400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573847400,"objectID":"e90315fa070f77cde9c32f8632395690","permalink":"/talk/imposter-effect-lightning-talk-meetingcpp19/","publishdate":"2019-12-13T23:03:14+01:00","relpermalink":"/talk/imposter-effect-lightning-talk-meetingcpp19/","section":"talk","summary":"A lightning talk about the imposter effect.","tags":["cpp","meetingcpp","cpp","talk"],"title":"Imposter Effect Lightning Talk Meetingcpp 2019","type":"talk"},{"authors":["Simon Renger"],"categories":["portfolio"],"content":"In this open world flight game my responsibilities vary from what is needed for the current state of development. Mainly I am focused with tools design and tools programming but also gameplay programming such as the camera. This project allows me to dive into Unity’s new Data-Oriented Technology Stack (DOTS) due to its massive performance promises especially in terms of level streaming.\nMy main responsibilities Making sure that we utilize DOTS to its fullest extent, research into how DOTS can improve our gameplay and allow for benefits. Besides, I am responsible for implementing a quest system with the help of DOTS.\n   Project Information      Type: Open World flight simulation game with focus on exploration an living world.   Duration: September 2019 - January 2020   Teamsize: 9 Programmers, 12 Designers, 8 Artists and 1 Producer   Roles: Tools programmer   Engine: Unity   Platform: Windows   Languages: C#   Technologies: Unity DOTS, Visual Studio, Jenkins, Perforce       Project Highlights     We are utilizing the new data oriented systems (DOTS) to allow a better open-world experience.    ","date":1569766200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569766200,"objectID":"ee1ab1170c7dcc1c012518077237f55d","permalink":"/project/seaplane/","publishdate":"2019-09-29T15:10:00+01:00","relpermalink":"/project/seaplane/","section":"project","summary":"Skye is an open world exploration flight game. Utilizing the new Data-Oriented Technology Stack (DOTS). Set in the Scottish Hebrides. [more information](/project/seaplane/)","tags":["windows","unity"],"title":"Skye (Published)","type":"project"},{"authors":["Simon Renger"],"categories":["portfolio"],"content":"The tomorrow engine is a cross platform C++ game framework which allows the creation of deterministic linear card games. The player had to fight the opponent and the 3 monsters in the game. The game we created with this was called Raptoads. The Framework supported Playstation 4 and Windows 10.\nGameplay trailer   My main responsibilities Apart from being the Tech lead / Team lead of the 11 programmers, I have been in charge for the core architecture. Besides, I have been responsible for implementing and designing the extensive tooling and pipeline for content creation and content management. The tooling was created in web technologies (electron \u0026amp; SQL Database), which allowed us for quick and rapid iterations.\nCore Architecture The application was split into four different modules. The Framework (TBSG) served the Client as well as the Server with basic utilities. Besides, we had the Network layer.\nWhen designing the modules, I followed the architecture guideline for our game: determinstic linear card games. That resulted in a \u0026ldquo;data oriented\u0026rdquo; approach.\nTooling - The Hub The framework came with its own tooling which was written in JavaScript and Electron. It served as the main content creation tool for Designers. The tool offered the following functions:\n AI Optimization for the QA Test games Modifiying the underlying content database (SQL) source contol of our Lua card scripts UI Editor Lua Script validation     Project Information      Duration: 16 Weeks - February to July 2019   Team size: 11 Programmers, 5 Designers, 8 Artists and 1 Producer   Roles: Tech Lead, Tools programmer, Scrum Master   Engine: Custom cross-platform C++ Engine with Electron Tooling (Tomorrow Engine)   Platform: Windows, Playstation 4   Languages: C++, JavaScript, Lua, SQL   Technologies: Lua Scripting, Online Crossplay Multiplayer, Event/HTTP/UI handling with PS4 Support.       Project Highlights     Scripting Pipeline: A Lua dialect which allowed designers to quickly develop with our tooling the card behaviour.   Scripting source control integration - via the tooling   Google Drive integration \u0026amp; Sheets   Utility AI - custimizeble via the tooling   Custom Tooling written with Web technologies for quick iterations, tool of choice: Electron \u0026amp; MariaDB   Playstation 4 Support: The engine supported Playstation 4    ","date":1556738340,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556738340,"objectID":"f2ee67ea04abfeaabd8b073b78e2a667","permalink":"/project/tbsg/","publishdate":"2019-05-01T20:19:00+01:00","relpermalink":"/project/tbsg/","section":"project","summary":"A multiplayer crossplatfrom c++ determinstic linear card game engine developed in 16 weeks. Targeted for Playstation 4 and Windows 10 [more information](/project/tbsg/)","tags":["cpp","ps4","windows"],"title":"“Tomorrow Engine“","type":"project"},{"authors":["Simon Renger"],"categories":["portfolio"],"content":"I have been giving workshops and lectures since my second year at the university. This is a great way of learning new skills and sharing the gained knowlegde with others. It also allows for a great flow of feedback. This is why I initiated the C++ learning comminity at our school (called C++ Guild)\nIn the last two years I have been giving various lectures and workshops on the following topics:\n   Lecture / Workshop Description     How do programmers think? A lecture which uses minecraft to illustrate how abstract thinking works as well as how we can improve communication internally.   C++ type deduction In three workshops I have covered the basics of the C++ type deduction: template type deduction, auto type deduction, decltype deduction, decltype auto deduction, lambda type deduction.   C++ Compiler and linker steps This presentation explained the compiler steps in C++ and the linker steps.   Allocators are handles to the heap This workshop introduced the concept of polymorphic memory allocations in C++17 and how to use them as well as how to implement them in C++14. Besides, there was a brief introduction on Memory Management.   C++ special member function rules In this talk I covered the special member function rules in C++.   C# for designers and artists This is a workshop series of 16 weeks in which me and 2 other students taught C# to fellow Design and Art students. We ran this course in year 2 and also in year 3. We iterated on the idea and changed the concept to a Quest-based learning environment. This allows students to progress at their own pace because they have an overview on how they progress.   C++ Memory Managment: Introduction In two parts I introduced Memory Managment in C++ and the underlying concepts.   C++ Memory Managment: Write your own STL compatible allocator This workshop explained how to implement in C++ 14 an STL compatible polymorphic like allocator and memory resource environment. This workshop was targeted for Windows and Playstation 4 and was held in 4 parts.    ","date":1544905140,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1544905140,"objectID":"090614a95d122e3de2e4615ff89dc3ec","permalink":"/project/tutoring/","publishdate":"2018-12-15T21:19:00+01:00","relpermalink":"/project/tutoring/","section":"project","summary":"Besides being a student I am giving lectures and workshops at university about serveral programming related topics: Memory Management, C# for Design an art and organizing the C++ learning community. How to programmer think? [more information](/project/tutoring/)","tags":["cpp","teaching","windows"],"title":"Tutoring","type":"project"}]